"""
Face authentication module for Customer agent - Optimized for real-time detection
"""
import os
import numpy as np
import json
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing

from ...utils.logger import log_info, log_error, log_warning
from ...neo4j_client.connection import execute_query_with_semaphore
from .customer_db import CustomerDB
from ...utils.cv2_wrapper import cv2
from insightface.model_zoo import get_model
from insightface.model_zoo.arcface_onnx import ArcFaceONNX
from insightface.utils.face_align import norm_crop
from insightface.app.common import Face
from insightface.model_zoo.retinaface import RetinaFace

# Th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
BASE_DIR = Path(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))).resolve()
# Th∆∞ m·ª•c ch·ª©a c√°c m√¥ h√¨nh
MODELS_DIR = BASE_DIR / 'app' / 'models'

class DetectedFace:
    def __init__(self, bbox, landmarks=None, confidence=None):
        self.bbox = bbox
        self.landmarks = landmarks
        self.confidence = confidence

class ArcFaceRecognizer:
    def __init__(self):
        model_dir = MODELS_DIR
        recog_model_path = os.path.join(model_dir, 'w600k_r50.onnx')
        self._recognizer = ArcFaceONNX(recog_model_path)
        self._recognizer.prepare(ctx_id=0)  # Use GPU if available

    def _convert_input_face(self, face: DetectedFace) -> Face:
        """Convert DetectedFace to InsightFace Face object"""
        try:
            kps = np.array([ 
                face.landmarks["left_eye"], 
                face.landmarks["right_eye"], 
                face.landmarks["nose"], 
                face.landmarks["left_mouth"], 
                face.landmarks["right_mouth"]
            ], dtype=np.float32)
            
            return Face(
                bbox=np.array([ 
                    face.bbox["x"], 
                    face.bbox["y"], 
                    face.bbox["x"] + face.bbox["w"], 
                    face.bbox["y"] + face.bbox["h"]
                ]),
                kps=kps,
                det_score=face.confidence
            )
        except Exception as e:
            log_error(f"‚ùå Error converting face: {str(e)}")
            return None

    def infer(self, image: np.ndarray, face: DetectedFace) -> Optional[np.ndarray]:
        """Extract face embedding from image"""
        try:
            converted_face = self._convert_input_face(face)
            if converted_face is None:
                return None

            aligned_face = norm_crop(image, converted_face.kps)
            if aligned_face is None:
                return None

            features = self._recognizer.get_feat(aligned_face)
            if features is not None and len(features.shape) == 2 and features.shape[0] == 1:
                features = features.squeeze(0)
            return features

        except Exception as e:
            log_error(f"‚ùå Error in face recognition: {str(e)}")
            return None

class FaceAuthManager:
    """
    Qu·∫£n l√Ω x√°c th·ª±c khu√¥n m·∫∑t s·ª≠ d·ª•ng m√¥ h√¨nh InsightFace
    S·ª≠ d·ª•ng m·∫´u Singleton ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ t·∫£i model m·ªôt l·∫ßn
    """
    _instance = None
    _loading_lock = threading.Lock()
    _detection_pool = ThreadPoolExecutor(max_workers=1)  # Ch·ªâ x·ª≠ l√Ω 1 frame t·∫°i m·ªôt th·ªùi ƒëi·ªÉm

    def __new__(cls):
        if cls._instance is None:
            log_info("üü¢ T·∫°o instance m·ªõi c·ªßa FaceAuthManager...")
            cls._instance = super(FaceAuthManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if getattr(self, '_initialized', False):
            return

        log_info("üü¢ ƒêang kh·ªüi t·∫°o FaceAuthManager...")
        
        # Kh·ªüi t·∫°o c√°c thu·ªôc t√≠nh c∆° b·∫£n
        self.models_ready = False
        self.use_real_model = False
        self.face_detector = None
        self.face_recognizer = None
        self.customer_db = None
        
        # T·ªëi ∆∞u c√°c ng∆∞·ª°ng cho x√°c th·ª±c th·ªùi gian th·ª±c
        self.detection_confidence_threshold = 0.15  # Gi·∫£m ng∆∞·ª°ng ph√°t hi·ªán ƒë·ªÉ d·ªÖ nh·∫≠n di·ªán h∆°n
        self.recognition_threshold = 0.25  # Gi·∫£m ng∆∞·ª°ng nh·∫≠n d·∫°ng
        self.max_faces_per_frame = 1  # Ch·ªâ x·ª≠ l√Ω 1 khu√¥n m·∫∑t

        # Cache v√† throttling settings
        self._last_detection_time = 0
        self._detection_cache = None
        self._detection_cache_ttl = 0.1  # 100ms gi·ªØa c√°c l·∫ßn ph√°t hi·ªán
        self._frame_skip_count = 0
        self._process_every_n_frames = 2  # X·ª≠ l√Ω 1 frame trong m·ªói 2 frame ƒë·ªÉ gi·∫£m t·∫£i

        # Session tracking
        self._last_auth_attempt = {}
        self._auth_attempt_timeout = 15  # Th·ªùi gian t·ªëi thi·ªÉu gi·ªØa c√°c l·∫ßn th·ª≠
        self._guest_mode_timeout = 15  # Chuy·ªÉn ch·∫ø ƒë·ªô kh√°ch sau 15 gi√¢y kh√¥ng x√°c th·ª±c ƒë∆∞·ª£c
        self._max_auth_attempts = 5  # S·ªë l·∫ßn th·ª≠ x√°c th·ª±c t·ªëi ƒëa
        self._auth_attempts = {}

        # Performance tracking
        self.last_detection_time = 0.0
        self.total_detection_time = 0.0
        self.detection_count = 0
        self._cache_hits = 0
        self._cache_misses = 0
        self._detection_errors = 0
        self._recognition_errors = 0

        # Cache cho embeddings
        self.all_customer_embeddings = []
        self.embeddings_loaded = False
        self._loading_embeddings = False
        self._loading_lock = threading.Lock()
        self._last_embedding_load_time = None
        self._embedding_cache_ttl = 300  # 5 minutes

        # Frame processing metrics
        self._frame_count = 0
        self._processed_frames = 0
        self._skipped_frames = 0
        self._frame_processing_times = []
        self._last_frame_time = None
        self._frame_interval = 0.1  # 100ms between frames
        self._min_processing_time = float('inf')
        self._max_processing_time = 0
        self._total_processing_time = 0
        
        # Session tracking
        self._last_auth_attempt = {}  # Track last auth attempt per session
        self._auth_attempt_timeout = 30  # 30 seconds between auth attempts
        self._guest_mode_timeout = 180  # 3 minutes before allowing guest mode
        self._max_auth_attempts = 3  # Maximum number of authentication attempts
        self._auth_attempts = {}  # Track number of attempts per session
        
        try:
            # Kh·ªüi t·∫°o customer database
            self.customer_db = CustomerDB()
            
            # Kh·ªüi t·∫°o models trong thread ri√™ng
            self._initialize_models_async()
            
            self._initialized = True
            log_info("‚úÖ FaceAuthManager initialized with basic settings")

        except Exception as e:
            log_error(f"‚ùå L·ªói kh·ªüi t·∫°o FaceAuthManager: {str(e)}")
            self._initialized = False
            raise

    def _initialize_models_async(self):
        """Kh·ªüi t·∫°o models trong thread ri√™ng"""
        def init_models():
            try:
                log_info("üöÄ B·∫Øt ƒë·∫ßu kh·ªüi t·∫°o models...")
                self._initialize_models()
                self.models_ready = True
                self.use_real_model = True
                log_info("‚úÖ Models kh·ªüi t·∫°o th√†nh c√¥ng")
                
                # Preload embeddings sau khi models ƒë√£ s·∫µn s√†ng
                log_info("üöÄ B·∫Øt ƒë·∫ßu preload face embeddings...")
                self._preload_embeddings_sync()
                
            except Exception as e:
                log_error(f"‚ùå L·ªói kh·ªüi t·∫°o models: {str(e)}")
                self.models_ready = False
                self.use_real_model = False

        # Ch·∫°y trong thread ri√™ng
        threading.Thread(target=init_models, daemon=True).start()

    def _initialize_models(self):
        """Kh·ªüi t·∫°o models t·ª´ model_manager"""
        try:
            model_dir = MODELS_DIR
            det_model_path = os.path.join(model_dir, 'det_10g.onnx')
            
            if not os.path.exists(det_model_path):
                raise FileNotFoundError(f"Detection model not found at {det_model_path}")
            
            log_info(f"üì¶ Loading RetinaFace model from {det_model_path}")
            
            # Initialize RetinaFace model with optimized settings
            self.face_detector = get_model(det_model_path)
            if self.face_detector is None:
                raise RuntimeError("Failed to initialize face detector")
                
            # Prepare model v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u
            self.face_detector.prepare(
                ctx_id=-1, 
                input_size=(640, 640), 
                det_thresh=self.detection_confidence_threshold
            )
            log_info("‚úÖ RetinaFace loaded successfully")

            # Kh·ªüi t·∫°o face recognizer
            recog_model_path = os.path.join(model_dir, 'w600k_r50.onnx')
            if not os.path.exists(recog_model_path):
                raise FileNotFoundError(f"Recognition model not found at {recog_model_path}")
            
            self.face_recognizer = ArcFaceRecognizer()
            if self.face_recognizer is None:
                raise RuntimeError("Failed to initialize face recognizer")

            log_info("‚úÖ Face recognition models initialized successfully")

        except Exception as e:
            log_error(f"‚ùå Error initializing models: {str(e)}")
            raise

    def recognize_face(self, frame):
        """Detect and recognize face in a single frame."""
        result = {'match': None, 'bbox': None, 'confidence': None, 'embedding': None}

        if frame is None:
            return result

        # Ki·ªÉm tra th·ªùi gian gi·ªØa c√°c l·∫ßn x·ª≠ l√Ω
        current_time = time.time()
        if current_time - self._last_detection_time < self._detection_cache_ttl:
            return result
        self._last_detection_time = current_time

        try:
            # Detect faces using RetinaFace
            bboxes, landmarks = self.face_detector.detect(frame, max_num=1, metric='default')
            
            if len(bboxes) == 0:
                return result  # Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t

            # L·∫•y khu√¥n m·∫∑t c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t
            bbox = bboxes[0]
            x1, y1, x2, y2, conf = bbox
            
            if conf < self.detection_confidence_threshold:
                return result  # ƒê·ªô tin c·∫≠y qu√° th·∫•p

            # Extract the bounding box and landmarks
            x1, y1, x2, y2 = bbox[:4].astype(int)
            result['bbox'] = [int(x1), int(y1), int(x2), int(y2)]
            result['confidence'] = float(conf)

            # Create a DetectedFace object with landmarks and bbox
            landmarks = landmarks[0]
            if landmarks.ndim == 2:
                landmarks = landmarks.flatten()

            try:
                face = DetectedFace(
                    bbox={"x": float(x1), "y": float(y1), "w": float(x2 - x1), "h": float(y2 - y1)},
                    landmarks={
                        "left_eye": (float(landmarks[0]), float(landmarks[1])),
                        "right_eye": (float(landmarks[2]), float(landmarks[3])),
                        "nose": (float(landmarks[4]), float(landmarks[5])),
                        "left_mouth": (float(landmarks[6]), float(landmarks[7])),
                        "right_mouth": (float(landmarks[8]), float(landmarks[9])),
                    },
                    confidence=float(conf)
                )

            except Exception as e:
                log_error(f"‚ùå L·ªói khi t·∫°o landmark cho ·∫£nh: {str(e)}")
                return result

            # Extract features using ArcFace
            embedding = self.face_recognizer.infer(frame, face)
            
            if embedding is not None and len(embedding.shape) == 2 and embedding.shape[0] == 1:
                embedding = embedding.squeeze(0)

            # Ki·ªÉm tra embedding h·ª£p l·ªá
            if embedding is None or embedding.ndim != 1 or np.linalg.norm(embedding) == 0:
                log_error("‚ùå Embedding t·ª´ frame kh√¥ng h·ª£p l·ªá.")
                result['match'] = False
                return result

            # L∆∞u embedding v√†o k·∫øt qu·∫£
            result['embedding'] = embedding

            # Compare with database
            match_info = self._find_matching_face_optimized(embedding)
            result['match'] = match_info if match_info else False

            return result

        except Exception as e:
            log_error(f"‚ùå Error during face recognition: {str(e)}")
            return result

    def verify_face_realtime(self, image, session_id: str = None, threshold=None):
        """X√°c th·ª±c khu√¥n m·∫∑t th·ªùi gian th·ª±c v·ªõi session tracking"""
        log_info(f"üîç Starting face verification for session {session_id}")
        frame_start_time = time.time()
        self._frame_count += 1
        
        # Validate input
        if image is None:
            log_error("‚ùå Input image is None")
            return {
                'success': False,
                'message': 'Kh√¥ng c√≥ h√¨nh ·∫£nh ƒë·∫ßu v√†o',
                'can_switch_guest': False,
                'frame_metrics': {
                    'frame_number': self._frame_count,
                    'error': 'No input image'
                }
            }

        # Log frame interval
        if self._last_frame_time is not None:
            frame_interval = frame_start_time - self._last_frame_time
            log_info(f"‚è±Ô∏è Frame interval: {frame_interval*1000:.1f}ms")
        self._last_frame_time = frame_start_time

        if threshold is None:
            threshold = self.recognition_threshold
            log_info(f"üìä Using default recognition threshold: {threshold}")

        # Ki·ªÉm tra th·ªùi gian gi·ªØa c√°c l·∫ßn x·ª≠ l√Ω
        current_time = time.time()
        if current_time - self._last_detection_time < self._detection_cache_ttl:
            self._skipped_frames += 1
            log_info(f"‚è≠Ô∏è Skipping frame {self._frame_count} (processing previous frame, cache TTL: {self._detection_cache_ttl*1000:.1f}ms)")
            return {
                'success': False,
                'message': 'ƒêang x·ª≠ l√Ω frame tr∆∞·ªõc ƒë√≥',
                'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                'frame_metrics': {
                    'frame_number': self._frame_count,
                    'skipped': True,
                    'processing_time': 0,
                    'cache_ttl': self._detection_cache_ttl
                }
            }
        self._last_detection_time = current_time

        # Ghi l·∫°i th·ªùi ƒëi·ªÉm th·ª≠ x√°c th·ª±c n·∫øu c√≥ session_id
        if session_id:
            self.record_auth_attempt(session_id)
            log_info(f"üìù Recorded auth attempt for session {session_id}")

        try:
            # Validate model readiness
            if not self.models_ready:
                log_error("‚ùå Face detection models not ready")
                return {
                    'success': False,
                    'message': 'H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t ch∆∞a s·∫µn s√†ng',
                    'can_switch_guest': False,
                    'frame_metrics': {
                        'frame_number': self._frame_count,
                        'error': 'Models not ready'
                    }
                }

            # Detect faces using RetinaFace with optimized settings
            detection_start = time.time()
            log_info(f"üîç Starting face detection on image shape: {image.shape}")
            bboxes, landmarks = self.face_detector.detect(image, max_num=1, metric='default')
            detection_time = time.time() - detection_start
            log_info(f"üîç Face detection completed in {detection_time*1000:.1f}ms")
            
            if len(bboxes) == 0:
                processing_time = time.time() - frame_start_time
                self._update_processing_metrics(processing_time)
                log_info("‚ùå No faces detected in frame")
                return {
                    'success': False,
                    'message': 'Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t',
                    'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                    'frame_metrics': {
                        'frame_number': self._frame_count,
                        'detection_time': detection_time,
                        'processing_time': processing_time
                    }
                }

            # L·∫•y khu√¥n m·∫∑t c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t
            bbox = bboxes[0]
            x1, y1, x2, y2, conf = bbox
            log_info(f"üéØ Detected face with confidence: {conf:.3f}")
            
            if conf < self.detection_confidence_threshold:
                processing_time = time.time() - frame_start_time
                self._update_processing_metrics(processing_time)
                log_info(f"‚ùå Face confidence {conf:.3f} below threshold {self.detection_confidence_threshold}")
                return {
                    'success': False,
                    'message': 'Khu√¥n m·∫∑t kh√¥ng ƒë·ªß r√µ r√†ng',
                    'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                    'frame_metrics': {
                        'frame_number': self._frame_count,
                        'detection_time': detection_time,
                        'processing_time': processing_time,
                        'confidence': conf,
                        'threshold': self.detection_confidence_threshold
                    }
                }

            # Extract the bounding box and landmarks
            x1, y1, x2, y2 = bbox[:4].astype(int)
            landmarks = landmarks[0]
            if landmarks.ndim == 2:
                landmarks = landmarks.flatten()

            # T·∫°o DetectedFace object v·ªõi landmarks v√† bbox
            try:
                face = DetectedFace(
                    bbox={"x": float(x1), "y": float(y1), "w": float(x2 - x1), "h": float(y2 - y1)},
                    landmarks={
                        "left_eye": (float(landmarks[0]), float(landmarks[1])),
                        "right_eye": (float(landmarks[2]), float(landmarks[3])),
                        "nose": (float(landmarks[4]), float(landmarks[5])),
                        "left_mouth": (float(landmarks[6]), float(landmarks[7])),
                        "right_mouth": (float(landmarks[8]), float(landmarks[9])),
                    },
                    confidence=float(conf)
                )
                log_info(f"‚úÖ Created DetectedFace object with bbox: {face.bbox}")
            except Exception as e:
                log_error(f"‚ùå Error creating DetectedFace object: {str(e)}")
                processing_time = time.time() - frame_start_time
                self._update_processing_metrics(processing_time)
                return {
                    'success': False,
                    'message': 'L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t',
                    'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                    'frame_metrics': {
                        'frame_number': self._frame_count,
                        'detection_time': detection_time,
                        'processing_time': processing_time,
                        'error': str(e)
                    }
                }

            # Extract embedding
            recognition_start = time.time()
            log_info("üîç Starting face recognition")
            embedding = self.face_recognizer.infer(image, face)
            recognition_time = time.time() - recognition_start
            log_info(f"üîç Face recognition completed in {recognition_time*1000:.1f}ms")

            if embedding is not None and len(embedding.shape) == 2 and embedding.shape[0] == 1:
                embedding = embedding.squeeze(0)

            if embedding is None or embedding.ndim != 1 or np.linalg.norm(embedding) == 0:
                processing_time = time.time() - frame_start_time
                self._update_processing_metrics(processing_time)
                log_error("‚ùå Invalid face embedding extracted")
                return {
                    'success': False,
                    'message': 'Kh√¥ng th·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t',
                    'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                    'frame_metrics': {
                        'frame_number': self._frame_count,
                        'detection_time': detection_time,
                        'recognition_time': recognition_time,
                        'processing_time': processing_time
                    }
                }

            # Compare with database
            matching_start = time.time()
            log_info("üîç Starting face matching")
            match_info = self._find_matching_face_optimized(embedding, threshold)
            matching_time = time.time() - matching_start
            log_info(f"üîç Face matching completed in {matching_time*1000:.1f}ms")

            processing_time = time.time() - frame_start_time
            self._update_processing_metrics(processing_time)
            self._processed_frames += 1

            result = {
                'success': bool(match_info),
                'customer': match_info if match_info else None,
                'can_switch_guest': False if match_info else self.can_switch_to_guest(session_id) if session_id else False,
                'frame_metrics': {
                    'frame_number': self._frame_count,
                    'detection_time': detection_time,
                    'recognition_time': recognition_time,
                    'matching_time': matching_time,
                    'total_processing_time': processing_time,
                    'confidence': conf
                }
            }

            if match_info:
                log_info(f"‚úÖ Face authentication successful: {match_info}")
            else:
                log_info("‚ùå No matching face found in database")
                result['message'] = 'Kh√¥ng t√¨m th·∫•y kh√°ch h√†ng kh·ªõp'

            return result

        except Exception as e:
            log_error(f"‚ùå Error in real-time face verification: {str(e)}")
            processing_time = time.time() - frame_start_time
            self._update_processing_metrics(processing_time)
            return {
                'success': False,
                'message': 'L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t',
                'can_switch_guest': self.can_switch_to_guest(session_id) if session_id else False,
                'frame_metrics': {
                    'frame_number': self._frame_count,
                    'processing_time': processing_time,
                    'error': str(e)
                }
            }

    def _update_processing_metrics(self, processing_time: float):
        """C·∫≠p nh·∫≠t c√°c metrics x·ª≠ l√Ω frame"""
        self._frame_processing_times.append(processing_time)
        self._min_processing_time = min(self._min_processing_time, processing_time)
        self._max_processing_time = max(self._max_processing_time, processing_time)
        self._total_processing_time += processing_time

        # Log metrics m·ªói 10 frames
        if self._frame_count % 10 == 0:
            avg_time = self._total_processing_time / max(1, self._processed_frames)
            log_info(f"""
üìä Frame Processing Metrics:
- Total frames: {self._frame_count}
- Processed frames: {self._processed_frames}
- Skipped frames: {self._skipped_frames}
- Min processing time: {self._min_processing_time*1000:.1f}ms
- Max processing time: {self._max_processing_time*1000:.1f}ms
- Average processing time: {avg_time*1000:.1f}ms
- Processing rate: {self._processed_frames/max(1, self._frame_count)*100:.1f}%
""")

    def get_frame_metrics(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ v·ªÅ x·ª≠ l√Ω frame"""
        avg_time = self._total_processing_time / max(1, self._processed_frames)
        return {
            'total_frames': self._frame_count,
            'processed_frames': self._processed_frames,
            'skipped_frames': self._skipped_frames,
            'min_processing_time': self._min_processing_time,
            'max_processing_time': self._max_processing_time,
            'average_processing_time': avg_time,
            'processing_rate': self._processed_frames/max(1, self._frame_count)*100
        }

    def _find_matching_face_optimized(self, embedding, threshold=0.35):
        """T√¨m khu√¥n m·∫∑t kh·ªõp trong database v·ªõi t·ªëi ∆∞u h√≥a"""
        if not self.embeddings_loaded:
            self.load_all_embeddings()

        best_match_info = None
        max_similarity = -1.0

        try:
            for customer in self.all_customer_embeddings:
                for db_embedding in customer['embeddings']:
                    if db_embedding.ndim != 1 or db_embedding.size == 0:
                        continue

                    if embedding.shape != db_embedding.shape:
                        continue

                    similarity = np.dot(embedding, db_embedding) / (
                        np.linalg.norm(embedding) * np.linalg.norm(db_embedding)
                    )
                    similarity = float(similarity)

                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_info = {
                            'name': customer['customer_name'],
                            'id': customer['customer_id'],
                            'similarity': similarity
                        }

            if best_match_info and max_similarity >= threshold:
                log_info(f"üéØ Match found: {best_match_info['name']} (ID: {best_match_info['id']}), Similarity: {max_similarity:.4f}")
                return {'name': best_match_info['name'], 'id': best_match_info['id']}

            return None

        except Exception as e:
            log_error(f"‚ùå Error finding matching face: {str(e)}")
            return None

    def get_face_embedding(self, image, return_detection_info=False):
        """
        Tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t t·ª´ h√¨nh ·∫£nh - Optimized version

        Args:
            image: H√¨nh ·∫£nh ƒë·∫ßu v√†o (numpy.ndarray t·ª´ camera)
            return_detection_info: C√≥ tr·∫£ v·ªÅ th√¥ng tin detection (bbox, confidence) kh√¥ng

        Returns:
            numpy.ndarray ho·∫∑c tuple:
            - N·∫øu return_detection_info=False: Vector ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t ho·∫∑c None
            - N·∫øu return_detection_info=True: (embedding, detection_info) ho·∫∑c (None, None)
        """
        start_time = time.time()

        try:
            log_info(f"üîç get_face_embedding: use_real_model={self.use_real_model}, image_shape={image.shape if image is not None else 'None'}")

            if not self.use_real_model or self.face_detector is None:
                log_warning("‚ö†Ô∏è S·ª≠ d·ª•ng m√¥ h√¨nh gi·∫£ l·∫≠p - kh√¥ng c√≥ m√¥ h√¨nh th·ª±c!")
                # S·ª≠ d·ª•ng vector gi·∫£ l·∫≠p n·∫øu kh√¥ng c√≥ m√¥ h√¨nh th·ª±c
                embedding = np.random.rand(512).astype(np.float32)
                embedding = embedding / np.linalg.norm(embedding)

                if return_detection_info:
                    # T·∫°o bounding box gi·∫£ l·∫≠p cho demo
                    h, w = image.shape[:2] if image is not None else (480, 640)
                    fake_bbox = [w//4, h//4, 3*w//4, 3*h//4]  # Gi·∫£ l·∫≠p bbox ·ªü gi·ªØa
                    detection_info = {
                        'bbox': fake_bbox,
                        'confidence': 0.95,
                        'landmarks': None
                    }
                    log_info(f"üé≠ T·∫°o fake detection: bbox={fake_bbox}, confidence=0.95")
                    return embedding, detection_info
                return embedding

            # Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi model t·ªëi ∆∞u
            detected_faces = self._detect_faces_optimized(image)

            if not detected_faces:
                log_warning("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong h√¨nh ·∫£nh")
                if return_detection_info:
                    return None, None
                return None

            # L·∫•y khu√¥n m·∫∑t c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t
            best_face = detected_faces[0]
            bbox = best_face['bbox']
            confidence = best_face['confidence']
            landmarks = best_face.get('landmarks', [])

            log_info(f"‚úÖ Ph√°t hi·ªán khu√¥n m·∫∑t: bbox={bbox}, confidence={confidence:.3f}")

            # Chu·∫©n b·ªã th√¥ng tin detection ƒë·ªÉ tr·∫£ v·ªÅ
            detection_info = {
                'bbox': bbox,  # [x1, y1, x2, y2]
                'confidence': confidence,
                'landmarks': landmarks
            }

            # Tr√≠ch xu·∫•t embedding t·ª´ face region
            embedding = self._extract_embedding_optimized(image, bbox)

            # Update performance metrics
            detection_time = time.time() - start_time
            self.last_detection_time = detection_time
            self.detection_count += 1
            self.total_detection_time += detection_time

            if return_detection_info:
                return embedding, detection_info
            return embedding

        except Exception as e:
            log_error(f"‚ùå L·ªói khi tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t: {str(e)}")
            if return_detection_info:
                return None, None
            return None

    def _detect_faces_optimized(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Ph√°t hi·ªán khu√¥n m·∫∑t t·ªëi ∆∞u v·ªõi ONNX model - Improved version
        """
        try:
            if self.face_detector is None:
                log_warning("‚ö†Ô∏è Face detector is None")
                return []

            log_info(f"üîç Starting face detection on image shape: {image.shape}")

            # Check if we can use cached result
            current_time = time.time()
            if (self._detection_cache is not None and
                current_time - self._last_detection_time < self._detection_cache_ttl):
                self._cache_hits = getattr(self, '_cache_hits', 0) + 1
                log_info(f"üìã Using cached detection result (age: {(current_time - self._last_detection_time)*1000:.1f}ms)")
                return self._detection_cache

            self._cache_misses = getattr(self, '_cache_misses', 0) + 1

            # Run detection directly on the image
            try:
                faces = self._run_detection(image, 1.0, 1.0, image.shape)

                # Enhanced face filtering
                valid_faces = []
                for face in faces:
                    if face['confidence'] > self.detection_confidence_threshold:
                        valid_faces.append(face)

                # Sort by confidence
                valid_faces.sort(key=lambda x: x['confidence'], reverse=True)

                # Limit max faces
                valid_faces = valid_faces[:self.max_faces_per_frame]

                # Cache result
                self._detection_cache = valid_faces
                self._last_detection_time = current_time

                log_info(f"üéØ Detection complete: {len(valid_faces)} high-quality faces found")
                return valid_faces

            except Exception as detection_error:
                log_error(f"‚ùå Detection execution error: {str(detection_error)}")
                self._detection_errors = getattr(self, '_detection_errors', 0) + 1
                return self._detection_cache or []

        except Exception as e:
            log_error(f"‚ùå Face detection error: {str(e)}")
            import traceback
            log_error(f"‚ùå Traceback: {traceback.format_exc()}")
            self._detection_errors = getattr(self, '_detection_errors', 0) + 1
            return []

    def _run_detection(self, processed_image: np.ndarray, scale_x: float, scale_y: float,
                      original_shape: Tuple[int, int, int]) -> List[Dict[str, Any]]:
        """Helper method to run actual detection in thread"""
        try:
            # Use the detect method instead of run
            bboxes, kpss = self.face_detector.detect(processed_image, max_num=self.max_faces_per_frame)
            
            faces = []
            if bboxes.shape[0] > 0:
                for i in range(bboxes.shape[0]):
                    bbox = bboxes[i, 0:4]
                    confidence = float(bboxes[i, 4])
                    
                    # Scale bbox back to original image coordinates
                    x1 = int(bbox[0] / scale_x)
                    y1 = int(bbox[1] / scale_y)
                    x2 = int(bbox[2] / scale_x)
                    y2 = int(bbox[3] / scale_y)
                    
                    # Clamp coordinates
                    h, w = original_shape[:2]
                    x1 = max(0, min(x1, w-1))
                    y1 = max(0, min(y1, h-1))
                    x2 = max(0, min(x2, w-1))
                    y2 = max(0, min(y2, h-1))
                    
                    if x2 <= x1 or y2 <= y1:
                        continue
                        
                    # Extract landmarks if available
                    landmarks = []
                    if kpss is not None and i < kpss.shape[0]:
                        kps = kpss[i]
                        for j in range(kps.shape[0]):
                            lx = int(kps[j, 0] / scale_x)
                            ly = int(kps[j, 1] / scale_y)
                            landmarks.append([lx, ly])
                    
                    face_info = {
                        'bbox': [x1, y1, x2, y2],
                        'confidence': confidence,
                        'landmarks': landmarks,
                        'area': (x2 - x1) * (y2 - y1)
                    }
                    
                    faces.append(face_info)
            
            return faces
            
        except Exception as e:
            log_error(f"‚ùå Error in _run_detection: {str(e)}")
            return []

    def _extract_embedding_optimized(self, image: np.ndarray, bbox: List[int]) -> Optional[np.ndarray]:
        """
        Extract embedding t·ª´ face region t·ªëi ∆∞u
        """
        try:
            if self.face_recognizer is None:
                log_error("‚ùå Face recognizer is not initialized")
                return None

            # Extract face region with margin
            face_region = self._extract_face_region(image, bbox)
            if face_region is None or face_region.size == 0:
                log_error("‚ùå Failed to extract face region")
                return None

            # Create DetectedFace object with bbox
            detected_face = DetectedFace(
                bbox={
                    'x': bbox[0],
                    'y': bbox[1],
                    'w': bbox[2] - bbox[0],
                    'h': bbox[3] - bbox[1]
                }
            )

            # Get embedding using face recognizer
            try:
                embedding = self.face_recognizer.infer(image, detected_face)
                if embedding is None:
                    log_error("‚ùå Face recognizer returned None embedding")
                    return None

                # Normalize embedding
                embedding = embedding / np.linalg.norm(embedding)
                return embedding

            except Exception as e:
                log_error(f"‚ùå Error during face recognition: {str(e)}")
                return None

        except Exception as e:
            log_error(f"‚ùå Error in _extract_embedding_optimized: {str(e)}")
            return None

    def _extract_face_region(self, image: np.ndarray, bbox: List[int], margin: float = 0.2) -> Optional[np.ndarray]:
        """
        Extract face region t·ª´ image v·ªõi margin
        """
        try:
            x1, y1, x2, y2 = bbox
            h, w = image.shape[:2]

            # Add margin
            face_w = x2 - x1
            face_h = y2 - y1
            margin_w = int(face_w * margin)
            margin_h = int(face_h * margin)

            # Expand bbox with margin
            x1_exp = max(0, x1 - margin_w)
            y1_exp = max(0, y1 - margin_h)
            x2_exp = min(w, x2 + margin_w)
            y2_exp = min(h, y2 + margin_h)

            # Extract face region
            face_region = image[y1_exp:y2_exp, x1_exp:x2_exp]

            return face_region

        except Exception as e:
            log_error(f"‚ùå L·ªói _extract_face_region: {str(e)}")
            return None

    def _preprocess_face(self, face_image: np.ndarray) -> np.ndarray:
        """
        Preprocess face image cho recognition model
        """
        # Resize to model input size
        resized = cv2.resize(face_image, (112, 112))

        # Convert to RGB
        rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)

        # Normalize to [-1, 1]
        normalized = (rgb_image.astype(np.float32) - 127.5) / 127.5

        # Transpose to CHW format and add batch dimension
        input_tensor = np.transpose(normalized, (2, 0, 1))[np.newaxis, ...]

        return input_tensor

    def can_switch_to_guest(self, session_id: str) -> bool:
        """Ki·ªÉm tra xem c√≥ th·ªÉ chuy·ªÉn sang guest mode kh√¥ng"""
        if not session_id:
            return False  # Kh√¥ng cho ph√©p chuy·ªÉn guest mode n·∫øu kh√¥ng c√≥ session_id
            
        if session_id not in self._last_auth_attempt:
            return False  # Kh√¥ng cho ph√©p chuy·ªÉn guest mode n·∫øu ch∆∞a c√≥ l·∫ßn th·ª≠ n√†o
            
        last_attempt = self._last_auth_attempt[session_id]
        time_since_attempt = time.time() - last_attempt
        
        # Ki·ªÉm tra s·ªë l·∫ßn th·ª≠ x√°c th·ª±c
        attempts = self._auth_attempts.get(session_id, 0)
        if attempts >= self._max_auth_attempts:
            log_info(f"‚úÖ Cho ph√©p chuy·ªÉn guest mode sau {attempts} l·∫ßn th·ª≠")
            return True
            
        # Ch·ªâ cho ph√©p chuy·ªÉn guest mode sau khi ƒë√£ ƒë·ª£i ƒë·ªß th·ªùi gian
        if time_since_attempt >= self._guest_mode_timeout:
            log_info(f"‚úÖ Cho ph√©p chuy·ªÉn guest mode sau {time_since_attempt:.1f}s")
            return True
            
        log_info(f"‚è≥ Ch∆∞a ƒë·ªß ƒëi·ªÅu ki·ªán chuy·ªÉn guest mode: {time_since_attempt:.1f}s < {self._guest_mode_timeout}s")
        return False

    def record_auth_attempt(self, session_id: str):
        """Ghi l·∫°i th·ªùi ƒëi·ªÉm th·ª≠ x√°c th·ª±c"""
        if not session_id:
            return
            
        current_time = time.time()
        self._last_auth_attempt[session_id] = current_time
        self._auth_attempts[session_id] = self._auth_attempts.get(session_id, 0) + 1
        
        log_info(f"üìù Ghi nh·∫≠n l·∫ßn th·ª≠ x√°c th·ª±c {self._auth_attempts[session_id]} cho session {session_id}")

    def get_performance_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ hi·ªáu su·∫•t"""
        return {
            'total_detections': self.detection_count,
            'avg_detection_time': self.total_detection_time / max(1, self.detection_count),
            'cache_hits': self._cache_hits,
            'cache_misses': self._cache_misses,
            'detection_errors': self._detection_errors,
            'recognition_errors': self._recognition_errors,
            'embeddings_loaded': self.embeddings_loaded,
            'total_customers': len(self.all_customer_embeddings)
        }

    def _preload_embeddings_sync(self):
        """T·∫£i embedding ƒë·ªìng b·ªô ngay khi kh·ªüi t·∫°o"""
        try:
            success = self.load_all_embeddings(force_reload=True)
            if success:
                log_info(f"‚úÖ Preload th√†nh c√¥ng {len(self.all_customer_embeddings)} customer embeddings")
            else:
                log_warning("‚ö†Ô∏è Preload embeddings th·∫•t b·∫°i, s·∫Ω t·∫£i lazy khi c·∫ßn")
        except Exception as e:
            log_error(f"‚ùå L·ªói khi preload embeddings: {str(e)}")

    def get_embeddings_stats(self):
        """L·∫•y th·ªëng k√™ v·ªÅ embeddings ƒë√£ t·∫£i"""
        if not self.embeddings_loaded:
            return {
                'loaded': False,
                'total_customers': 0,
                'total_embeddings': 0,
                'load_time': None
            }

        total_embeddings = sum(len(customer['embeddings']) for customer in self.all_customer_embeddings)
        return {
            'loaded': True,
            'total_customers': len(self.all_customer_embeddings),
            'total_embeddings': total_embeddings,
            'load_time': self._last_embedding_load_time,
            'cache_ttl': self._embedding_cache_ttl
        }

    def preload_embeddings_async(self):
        """Preload face embeddings asynchronously"""
        try:
            # Ch·ªâ load face detection model n·∫øu ch∆∞a ƒë∆∞·ª£c load
            from app.models.model_manager import ModelManager
            model_manager = ModelManager()
            if not model_manager.face_detection_model:
                model_manager._load_face_detection_model()
                log_info("‚úÖ Face detection model loaded successfully")
            
            # Load face embeddings
            self._load_face_embeddings()
            log_info("‚úÖ Face embeddings loaded successfully")
        except Exception as e:
            log_error(f"‚ùå Error preloading face embeddings: {str(e)}")
            import traceback
            log_error(f"Error details: {traceback.format_exc()}")

    def load_all_embeddings(self, force_reload=False):
        """
        T·∫£i t·∫•t c·∫£ embedding c·ªßa kh√°ch h√†ng t·ª´ Neo4j
        S·ª≠ d·ª•ng lock ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ m·ªôt thread t·∫£i embedding t·∫°i m·ªôt th·ªùi ƒëi·ªÉm
        S·ª≠ d·ª•ng cache ƒë·ªÉ tr√°nh t·∫£i l·∫°i embedding qu√° th∆∞·ªùng xuy√™n

        Args:
            force_reload: Bu·ªôc t·∫£i l·∫°i embedding ngay c·∫£ khi cache c√≤n hi·ªáu l·ª±c

        Returns:
            bool: True n·∫øu t·∫£i th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
        """
        # Ki·ªÉm tra xem c√≥ thread kh√°c ƒëang t·∫£i embedding kh√¥ng
        if self._loading_embeddings:
            log_info("‚è≥ ƒêang c√≥ thread kh√°c t·∫£i embedding, ch·ªù ho√†n th√†nh...")
            # Ch·ªù t·ªëi ƒëa 5 gi√¢y
            start_time = time.time()
            while self._loading_embeddings and time.time() - start_time < 5:
                time.sleep(0.1)

            # N·∫øu ƒë√£ t·∫£i xong, tr·∫£ v·ªÅ k·∫øt qu·∫£
            if self.embeddings_loaded:
                return True
            else:
                log_warning("‚è≥ Ch·ªù qu√° l√¢u cho thread kh√°c t·∫£i embedding, ti·∫øp t·ª•c v·ªõi thread hi·ªán t·∫°i")

        # Ki·ªÉm tra cache n·∫øu kh√¥ng bu·ªôc t·∫£i l·∫°i
        if not force_reload and self.embeddings_loaded and self._last_embedding_load_time:
            # Ki·ªÉm tra xem cache c√≥ c√≤n hi·ªáu l·ª±c kh√¥ng
            cache_age = (datetime.now() - self._last_embedding_load_time).total_seconds()
            if cache_age < self._embedding_cache_ttl:
                log_info(f"‚úÖ S·ª≠ d·ª•ng cache embedding (tu·ªïi: {cache_age:.1f}s < TTL: {self._embedding_cache_ttl}s)")
                return True

        # S·ª≠ d·ª•ng lock ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ m·ªôt thread t·∫£i embedding t·∫°i m·ªôt th·ªùi ƒëi·ªÉm
        with self._loading_lock:
            # Ki·ªÉm tra l·∫°i sau khi c√≥ lock (c√≥ th·ªÉ thread kh√°c ƒë√£ t·∫£i xong)
            if not force_reload and self.embeddings_loaded and self._last_embedding_load_time:
                cache_age = (datetime.now() - self._last_embedding_load_time).total_seconds()
                if cache_age < self._embedding_cache_ttl:
                    log_info(f"‚úÖ S·ª≠ d·ª•ng cache embedding sau khi c√≥ lock (tu·ªïi: {cache_age:.1f}s)")
                    return True

            # ƒê√°nh d·∫•u ƒëang t·∫£i embedding
            self._loading_embeddings = True

            try:
                log_info("üì¶ ƒêang t·∫£i t·∫•t c·∫£ embedding c·ªßa kh√°ch h√†ng t·ª´ Neo4j...")

                # Query ƒë·ªÉ l·∫•y face embeddings th·ª±c t·∫ø t·ª´ database
                query = """
                MATCH (c:Customer)
                WHERE c.embedding IS NOT NULL
                RETURN c.id as id, c.name as name, c.embedding as embedding
                """

                log_info("üîç ƒêang truy v·∫•n face embeddings t·ª´ Neo4j...")
                result = execute_query_with_semaphore(
                    query,
                    use_cache=True,
                    max_retries=5,
                    retry_delay=2,
                    semaphore_timeout=30
                )

                if not result:
                    log_warning("‚ùå Kh√¥ng t√¨m th·∫•y kh√°ch h√†ng n√†o c√≥ embedding trong c∆° s·ªü d·ªØ li·ªáu")
                    self.embeddings_loaded = False
                    return False

                log_info(f"‚úÖ T√¨m th·∫•y {len(result)} kh√°ch h√†ng c√≥ embedding")

                # X√≥a cache c≈©
                self.all_customer_embeddings = []

                # X·ª≠ l√Ω k·∫øt qu·∫£ truy v·∫•n
                for customer in result:
                    customer_id = customer['id']
                    customer_name = customer['name']

                    log_info(f"üîç X·ª≠ l√Ω kh√°ch h√†ng: {customer_name} (ID: {customer_id})")
                    log_info(f"üìã D·ªØ li·ªáu kh√°ch h√†ng: {list(customer.keys())}")

                    # Ki·ªÉm tra format m·ªõi tr∆∞·ªõc (4 embedding ri√™ng bi·ªát)
                    if 'embedding1' in customer:
                        log_info(f"üì¶ T√¨m th·∫•y format m·ªõi (4 embedding ri√™ng bi·ªát) cho {customer_name}")
                        embeddings = []
                        for i in range(1, 5):
                            emb_key = f'embedding{i}'
                            if customer.get(emb_key):
                                try:
                                    emb_data = json.loads(customer[emb_key])
                                    embeddings.append(np.array(emb_data, dtype=np.float32))
                                    log_info(f"‚úÖ T·∫£i embedding {i} cho {customer_name}")
                                except Exception as e:
                                    log_warning(f"‚ùå L·ªói t·∫£i embedding {i} cho {customer_name}: {str(e)}")
                                    continue

                        if embeddings:
                            self.all_customer_embeddings.append({
                                'customer_id': customer_id,
                                'customer_name': customer_name,
                                'embeddings': embeddings
                            })
                            log_info(f"‚úÖ T·∫£i {len(embeddings)} embedding cho kh√°ch h√†ng {customer_name}")
                        else:
                            log_warning(f"‚ö†Ô∏è Kh√¥ng c√≥ embedding h·ª£p l·ªá n√†o cho {customer_name}")
                        continue

                    # X·ª≠ l√Ω format c≈© (embedding array)
                    embedding_data = customer.get('embedding')
                    if not embedding_data:
                        log_warning(f"‚ùå Kh√¥ng t√¨m th·∫•y embedding c·ªßa kh√°ch h√†ng {customer_name} (ID: {customer_id})")
                        continue

                    try:
                        # Debug: In ra format c·ªßa embedding_data
                        log_info(f"üîç Debug embedding format cho {customer_name}: type={type(embedding_data)}, len={len(embedding_data) if hasattr(embedding_data, '__len__') else 'N/A'}")
                        if hasattr(embedding_data, '__len__') and len(embedding_data) > 0:
                            log_info(f"üîç First element type: {type(embedding_data[0])}, sample: {str(embedding_data[0])[:100]}...")

                        # X·ª≠ l√Ω embedding data
                        parsed_embeddings = None

                        if isinstance(embedding_data, str):
                            # Embedding ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng JSON string, c·∫ßn parse
                            log_info(f"üìù Parsing JSON string embedding cho {customer_name}")
                            try:
                                parsed_embeddings = json.loads(embedding_data)
                                log_info(f"‚úÖ Parse JSON th√†nh c√¥ng: type={type(parsed_embeddings)}, len={len(parsed_embeddings) if hasattr(parsed_embeddings, '__len__') else 'N/A'}")
                            except json.JSONDecodeError as e:
                                log_error(f"‚ùå L·ªói parse JSON cho {customer_name}: {str(e)}")
                                continue
                        elif isinstance(embedding_data, list):
                            # Embedding ƒë√£ l√† list
                            parsed_embeddings = embedding_data
                            log_info(f"‚úÖ Embedding ƒë√£ l√† list cho {customer_name}")
                        else:
                            log_warning(f"‚ùå Format embedding kh√¥ng h·ªó tr·ª£ cho {customer_name}: type={type(embedding_data)}")
                            continue

                        # Chuy·ªÉn ƒë·ªïi embedding th√†nh numpy array
                        if isinstance(parsed_embeddings, list) and len(parsed_embeddings) > 0:
                            numpy_embeddings = []
                            for i, emb in enumerate(parsed_embeddings):
                                if isinstance(emb, list) and len(emb) > 0:
                                    numpy_embedding = np.array(emb, dtype=np.float32)
                                    numpy_embeddings.append(numpy_embedding)
                                    log_info(f"‚úÖ T·∫£i embedding {i+1} cho {customer_name} (shape: {numpy_embedding.shape})")

                            if numpy_embeddings:
                                # L∆∞u th√¥ng tin kh√°ch h√†ng v√† embedding v√†o cache
                                self.all_customer_embeddings.append({
                                    'customer_id': customer_id,
                                    'customer_name': customer_name,
                                    'embeddings': numpy_embeddings
                                })
                                log_info(f"‚úÖ T·∫£i {len(numpy_embeddings)} embedding cho kh√°ch h√†ng {customer_name}")
                            else:
                                log_warning(f"‚ö†Ô∏è Kh√¥ng c√≥ embedding h·ª£p l·ªá n√†o cho {customer_name}")
                        else:
                            log_warning(f"‚ùå Parsed embedding kh√¥ng ph·∫£i list h·ª£p l·ªá cho {customer_name}: type={type(parsed_embeddings)}")
                            continue

                    except Exception as e:
                        log_error(f"‚ùå L·ªói khi x·ª≠ l√Ω embedding c·ªßa kh√°ch h√†ng {customer_name} (ID: {customer_id}): {str(e)}")
                        continue

                log_info(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng embedding c·ªßa {len(self.all_customer_embeddings)} kh√°ch h√†ng")
                self.embeddings_loaded = True
                self._last_embedding_load_time = datetime.now()
                return True

            except Exception as e:
                log_error(f"‚ùå L·ªói khi t·∫£i embedding c·ªßa kh√°ch h√†ng: {str(e)}")
                self.embeddings_loaded = False
                return False
            finally:
                # ƒê·∫£m b·∫£o reset tr·∫°ng th√°i ƒëang t·∫£i
                self._loading_embeddings = False

    def verify_face(self, image, threshold=0.01, return_top_matches=True):
        """
        X√°c minh khu√¥n m·∫∑t trong h√¨nh ·∫£nh v·ªõi c∆° s·ªü d·ªØ li·ªáu

        Args:
            image: H√¨nh ·∫£nh ƒë·∫ßu v√†o (numpy.ndarray ho·∫∑c ƒë∆∞·ªùng d·∫´n file)
            threshold: Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng ƒë·ªÉ x√°c ƒë·ªãnh kh·ªõp
            return_top_matches: Tr·∫£ v·ªÅ danh s√°ch c√°c khu√¥n m·∫∑t kh·ªõp nh·∫•t

        Returns:
            dict: K·∫øt qu·∫£ x√°c minh khu√¥n m·∫∑t bao g·ªìm th√¥ng tin detection
        """
        # Ki·ªÉm tra xem ƒë√£ t·∫£i embedding ch∆∞a (ƒë√£ preload khi kh·ªüi t·∫°o)
        if not self.embeddings_loaded:
            log_warning("‚ùå Embeddings ch∆∞a ƒë∆∞·ª£c preload, h·ªá th·ªëng ch∆∞a s·∫µn s√†ng")
            return {
                'success': False,
                'message': 'H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t ch∆∞a s·∫µn s√†ng'
            }

        # Ki·ªÉm tra xem c√≥ embedding n√†o kh√¥ng
        if not self.all_customer_embeddings:
            log_warning("‚ùå Kh√¥ng c√≥ kh√°ch h√†ng n√†o c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t trong c∆° s·ªü d·ªØ li·ªáu")
            return {
                'success': False,
                'message': 'Kh√¥ng c√≥ kh√°ch h√†ng n√†o c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t trong c∆° s·ªü d·ªØ li·ªáu'
            }

        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t v·ªõi th√¥ng tin detection
        embedding, detection_info = self.get_face_embedding(image, return_detection_info=True)
        if embedding is None:
            log_warning("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong h√¨nh ·∫£nh")
            return {
                'success': False,
                'message': 'Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong h√¨nh ·∫£nh',
                'bbox': None,
                'confidence': None
            }

        # So s√°nh v·ªõi c∆° s·ªü d·ªØ li·ªáu
        result = self._find_matching_face(embedding, threshold)

        if result['success']:
            # L·∫•y th√¥ng tin chi ti·∫øt c·ªßa kh√°ch h√†ng
            customer_id = result['customer_id']

            # S·ª≠ d·ª•ng cache cho th√¥ng tin kh√°ch h√†ng v√† ƒë∆°n h√†ng
            try:
                customer_info = self.customer_db.get_customer_info(customer_id)
                customer_orders = self.customer_db.get_customer_orders(customer_id)
            except Exception as e:
                log_error(f"‚ùå L·ªói khi l·∫•y th√¥ng tin kh√°ch h√†ng: {str(e)}")
                customer_info = None
                customer_orders = []

            log_info(f"‚úÖ X√°c minh khu√¥n m·∫∑t th√†nh c√¥ng: {result['customer_name']} (ID: {customer_id}, Similarity: {result['similarity']:.4f})")
            return {
                'success': True,
                'customer_id': customer_id,
                'customer_name': result['customer_name'],
                'similarity': result['similarity'],
                'customer_info': customer_info,
                'customer_orders': customer_orders,
                'top_matches': result.get('top_matches', []),
                # Th√™m th√¥ng tin detection
                'bbox': detection_info['bbox'] if detection_info else None,
                'confidence': detection_info['confidence'] if detection_info else None,
                'landmarks': detection_info.get('landmarks') if detection_info else None
            }
        else:
            log_warning(f"‚ùå X√°c minh khu√¥n m·∫∑t th·∫•t b·∫°i: {result['message']}")
            return {
                'success': False,
                'message': result['message'],
                'similarity': result.get('similarity'),
                'top_matches': result.get('top_matches', []),
                # Th√™m th√¥ng tin detection ngay c·∫£ khi th·∫•t b·∫°i (ƒë·ªÉ hi·ªÉn th·ªã bbox)
                'bbox': detection_info['bbox'] if detection_info else None,
                'confidence': detection_info['confidence'] if detection_info else None,
                'landmarks': detection_info.get('landmarks') if detection_info else None
            }

    def _find_matching_face(self, embedding, threshold=0.01):
        """
        T√¨m khu√¥n m·∫∑t kh·ªõp trong c∆° s·ªü d·ªØ li·ªáu

        Args:
            embedding: Vector ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t
            threshold: Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng

        Returns:
            dict: K·∫øt qu·∫£ t√¨m ki·∫øm
        """
        # Gi·∫£ ƒë·ªãnh r·∫±ng embeddings ƒë√£ ƒë∆∞·ª£c t·∫£i tr∆∞·ªõc khi g·ªçi ph∆∞∆°ng th·ª©c n√†y
        # Ph∆∞∆°ng th·ª©c verify_face ƒë√£ ki·ªÉm tra v√† t·∫£i embedding n·∫øu c·∫ßn

        # Ki·ªÉm tra xem c√≥ embedding n√†o kh√¥ng
        if not self.all_customer_embeddings:
            log_warning("‚ùå Kh√¥ng c√≥ kh√°ch h√†ng n√†o c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t trong c∆° s·ªü d·ªØ li·ªáu")
            return {
                'success': False,
                'message': 'Kh√¥ng c√≥ kh√°ch h√†ng n√†o c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t trong c∆° s·ªü d·ªØ li·ªáu'
            }

        best_match = None
        max_similarity = -1
        all_matches = []  # Danh s√°ch t·∫•t c·∫£ c√°c k·∫øt qu·∫£ kh·ªõp

        # So s√°nh v·ªõi t·∫•t c·∫£ embedding ƒë√£ t·∫£i
        log_info(f"üîç B·∫Øt ƒë·∫ßu so s√°nh v·ªõi {len(self.all_customer_embeddings)} kh√°ch h√†ng trong database")

        for customer in self.all_customer_embeddings:
            customer_id = customer['customer_id']
            customer_name = customer['customer_name']
            customer_embeddings = customer['embeddings']

            for i, db_embedding in enumerate(customer_embeddings):
                # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine
                similarity = np.dot(embedding, db_embedding) / (
                    np.linalg.norm(embedding) * np.linalg.norm(db_embedding)
                )

                log_info(f"üìä So s√°nh v·ªõi {customer_name} (embedding {i+1}): similarity={float(similarity):.4f}")

                # L∆∞u k·∫øt qu·∫£ kh·ªõp
                all_matches.append({
                    'customer_id': customer_id,
                    'customer_name': customer_name,
                    'similarity': float(similarity)
                })

                # C·∫≠p nh·∫≠t k·∫øt qu·∫£ kh·ªõp t·ªët nh·∫•t
                if similarity > max_similarity:
                    max_similarity = similarity
                    best_match = {
                        'customer_id': customer_id,
                        'customer_name': customer_name,
                        'similarity': float(similarity)
                    }
                    log_info(f"üéØ T√¨m th·∫•y match t·ªët h∆°n: {customer_name} v·ªõi similarity={float(similarity):.4f}")

        # S·∫Øp x·∫øp t·∫•t c·∫£ k·∫øt qu·∫£ kh·ªõp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·∫£m d·∫ßn
        all_matches = sorted(all_matches, key=lambda x: x['similarity'], reverse=True)

        log_info(f"üèÜ K·∫øt qu·∫£ so s√°nh: max_similarity={float(max_similarity):.4f}, threshold={threshold}")
        log_info(f"üìã Top 3 matches: {all_matches[:3]}")

        if best_match and max_similarity >= threshold:
            log_info(f"‚úÖ T√¨m th·∫•y kh√°ch h√†ng kh·ªõp: {best_match['customer_name']} v·ªõi similarity={float(max_similarity):.4f}")
            return {
                'success': True,
                'customer_id': best_match['customer_id'],
                'customer_name': best_match['customer_name'],
                'similarity': best_match['similarity'],
                'top_matches': all_matches[:5]  # Tr·∫£ v·ªÅ 5 k·∫øt qu·∫£ kh·ªõp t·ªët nh·∫•t
            }
        else:
            log_warning(f"‚ùå Kh√¥ng t√¨m th·∫•y kh√°ch h√†ng kh·ªõp (max_similarity={float(max_similarity):.4f} < threshold={threshold})")
            return {
                'success': False,
                'message': 'Kh√¥ng t√¨m th·∫•y kh√°ch h√†ng kh·ªõp v·ªõi khu√¥n m·∫∑t n√†y',
                'similarity': float(max_similarity) if max_similarity > -1 else None,
                'top_matches': all_matches[:5]  # Tr·∫£ v·ªÅ 5 k·∫øt qu·∫£ kh·ªõp t·ªët nh·∫•t
            }

    def update_settings(self, settings: Dict[str, Any]):
        """
        C·∫≠p nh·∫≠t settings c·ªßa face authentication
        """
        if 'detection_confidence_threshold' in settings:
            self.detection_confidence_threshold = settings['detection_confidence_threshold']
            log_info(f"‚úÖ Updated detection_confidence_threshold: {self.detection_confidence_threshold}")

        if 'recognition_threshold' in settings:
            self.recognition_threshold = settings['recognition_threshold']
            log_info(f"‚úÖ Updated recognition_threshold: {self.recognition_threshold}")

        if 'process_every_n_frames' in settings:
            self._process_every_n_frames = settings['process_every_n_frames']
            log_info(f"‚úÖ Updated process_every_n_frames: {self._process_every_n_frames}")

        if 'detection_cache_ttl' in settings:
            self._detection_cache_ttl = settings['detection_cache_ttl']
            log_info(f"‚úÖ Updated detection_cache_ttl: {self._detection_cache_ttl}")

        if 'max_faces_per_frame' in settings:
            self.max_faces_per_frame = settings['max_faces_per_frame']
            log_info(f"‚úÖ Updated max_faces_per_frame: {self.max_faces_per_frame}")

        log_info(f"‚úÖ FaceAuthManager settings updated: {settings}")

# T·∫°o singleton instance khi module ƒë∆∞·ª£c import
face_auth_manager = FaceAuthManager()
