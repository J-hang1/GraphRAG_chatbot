"""
Module cung cáº¥p cÃ¡c chá»©c nÄƒng so sÃ¡nh ngá»¯ nghÄ©a giá»¯a thá»±c thá»ƒ vÃ  tá»« khÃ³a
"""
import numpy as np
from typing import List, Dict, Any, Tuple, Optional, Union
from sklearn.metrics.pairwise import cosine_similarity
import logging

from app.utils.logger import log_info, log_error
from ..core.core_functions import compute_entity_semantic_similarity, get_phobert_manager
from ...neo4j_client.connection import execute_query
from ..core.constants import QUERY_TEMPLATES

# NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a
SEMANTIC_SIMILARITY_THRESHOLD = 0.6

# Tá»« Ä‘iá»ƒn Ä‘á»“ng nghÄ©a vÃ  biáº¿n thá»ƒ
SEMANTIC_EQUIVALENTS = {
    "cÃ  phÃª": ["cafe", "coffee", "espresso", "cappuccino", "latte"],
    "Ã­t Ä‘Æ°á»ng": ["Ã­t ngá»t", "khÃ´ng ngá»t", "giáº£m Ä‘Æ°á»ng", "low sugar"],
    "sá»¯a": ["milk", "cream", "dairy", "kem sá»¯a", "sá»¯a tÆ°Æ¡i"],
    "espresso": ["cÃ  phÃª espresso", "espresso coffee", "cÃ  phÃª Ä‘áº­m Ä‘áº·c"],
    "ngá»t": ["Ä‘Æ°á»ng", "sugar", "sweet"],
    "Ä‘áº¯ng": ["bitter", "strong", "máº¡nh"],
    # ThÃªm cÃ¡c tá»« khÃ³a khÃ¡c...
}

def enhance_keywords_for_entity_matching(keywords: List[str]) -> List[str]:
    """
    Má»Ÿ rá»™ng vÃ  cáº£i thiá»‡n danh sÃ¡ch tá»« khÃ³a cho viá»‡c so sÃ¡nh thá»±c thá»ƒ

    Args:
        keywords: Danh sÃ¡ch tá»« khÃ³a ban Ä‘áº§u

    Returns:
        Danh sÃ¡ch tá»« khÃ³a Ä‘Ã£ Ä‘Æ°á»£c má»Ÿ rá»™ng
    """
    enhanced_keywords = []
    for keyword in keywords:
        enhanced_keywords.append(keyword)
        # ThÃªm cÃ¡c tá»« Ä‘á»“ng nghÄ©a vÃ  biáº¿n thá»ƒ
        for key, equivalents in SEMANTIC_EQUIVALENTS.items():
            if keyword.lower() in key.lower() or any(keyword.lower() in eq.lower() for eq in equivalents):
                enhanced_keywords.extend(equivalents)
                enhanced_keywords.append(key)

    # Loáº¡i bá» cÃ¡c tá»« khÃ³a trÃ¹ng láº·p vÃ  chuáº©n hÃ³a
    return list(set([k.lower().strip() for k in enhanced_keywords]))

# Function moved to core_functions.py

def compute_entity_semantic_scores(entity: Dict[str, Any], keywords: List[str]) -> Dict[str, float]:
    """
    TÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ ngá»¯ nghÄ©a cho má»™t thá»±c thá»ƒ vá»›i nhiá»u tá»« khÃ³a

    Args:
        entity: ThÃ´ng tin vá» thá»±c thá»ƒ
        keywords: Danh sÃ¡ch tá»« khÃ³a

    Returns:
        Dictionary chá»©a Ä‘iá»ƒm sá»‘ cho má»—i tá»« khÃ³a vÃ  Ä‘iá»ƒm tá»•ng
    """
    entity_name = entity.get("name", "")
    entity_type = entity.get("type", "")
    entity_original_name = entity.get("original_name", "")

    # Táº¡o vÄƒn báº£n thá»±c thá»ƒ
    entity_texts = []
    if entity_name:
        entity_texts.append(entity_name)
    if entity_type:
        entity_texts.append(entity_type)
    if entity_original_name and entity_original_name != entity_name:
        entity_texts.append(entity_original_name)

    entity_text = " ".join(entity_texts)

    # TÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ cho má»—i tá»« khÃ³a
    scores = {}
    max_score = 0
    max_keyword = ""

    for keyword in keywords:
        score = compute_entity_semantic_similarity(entity_text, keyword)
        scores[keyword] = score

        if score > max_score:
            max_score = score
            max_keyword = keyword

    # ThÃªm Ä‘iá»ƒm tá»•ng vÃ  tá»« khÃ³a tá»‘t nháº¥t
    scores["max_score"] = max_score
    scores["max_keyword"] = max_keyword
    scores["is_match"] = max_score >= SEMANTIC_SIMILARITY_THRESHOLD

    return scores

def find_matching_entities_semantic(entities: List[Dict[str, Any]], keywords: List[str]) -> Tuple[List[Dict[str, Any]], int]:
    """
    TÃ¬m cÃ¡c thá»±c thá»ƒ khá»›p vá»›i tá»« khÃ³a dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a

    Args:
        entities: Danh sÃ¡ch thá»±c thá»ƒ
        keywords: Danh sÃ¡ch tá»« khÃ³a

    Returns:
        Tuple chá»©a danh sÃ¡ch thá»±c thá»ƒ khá»›p vÃ  sá»‘ lÆ°á»£ng thá»±c thá»ƒ khá»›p
    """
    # Má»Ÿ rá»™ng danh sÃ¡ch tá»« khÃ³a
    enhanced_keywords = enhance_keywords_for_entity_matching(keywords)
    log_info(f"Danh sÃ¡ch tá»« khÃ³a Ä‘Ã£ Ä‘Æ°á»£c má»Ÿ rá»™ng: {enhanced_keywords}")

    matching_entities = []
    matching_count = 0

    for entity in entities:
        # TÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ ngá»¯ nghÄ©a
        semantic_scores = compute_entity_semantic_scores(entity, enhanced_keywords)

        # ThÃªm Ä‘iá»ƒm sá»‘ vÃ o thá»±c thá»ƒ
        entity["semantic_scores"] = semantic_scores

        # Kiá»ƒm tra xem thá»±c thá»ƒ cÃ³ khá»›p khÃ´ng
        if semantic_scores["is_match"]:
            matching_count += 1
            matching_entities.append(entity)

    return matching_entities, matching_count

def post_process_with_semantic_similarity(results: List[Dict[str, Any]], keywords: List[str]) -> List[Dict[str, Any]]:
    """
    Háº­u xá»­ lÃ½ káº¿t quáº£ vá»›i Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a

    Args:
        results: Danh sÃ¡ch káº¿t quáº£ tá»« truy váº¥n Neo4j
        keywords: Danh sÃ¡ch tá»« khÃ³a

    Returns:
        Danh sÃ¡ch káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
    """
    # Má»Ÿ rá»™ng danh sÃ¡ch tá»« khÃ³a
    enhanced_keywords = enhance_keywords_for_entity_matching(keywords)

    # Láº¥y PhoBERT manager
    phobert_manager = get_phobert_manager()

    # Äáº£m báº£o PhoBERT Ä‘Ã£ Ä‘Æ°á»£c táº£i
    if not phobert_manager.is_loaded and not phobert_manager.wait_for_model(timeout=30):
        log_error("KhÃ´ng thá»ƒ táº£i PhoBERT model Ä‘á»ƒ háº­u xá»­ lÃ½ káº¿t quáº£")
        return results

    # Xá»­ lÃ½ tá»«ng káº¿t quáº£
    for result in results:
        # Láº¥y thÃ´ng tin sáº£n pháº©m
        product_name = result.get("product_name", "")
        product_description = result.get("product_description", "")

        # Táº¡o vÄƒn báº£n sáº£n pháº©m
        product_text = f"{product_name} {product_description}".strip()

        # TÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ ngá»¯ nghÄ©a cho sáº£n pháº©m
        semantic_scores = {}
        total_semantic_score = 0

        for keyword in enhanced_keywords:
            score = compute_entity_semantic_similarity(product_text, keyword)
            semantic_scores[keyword] = score
            total_semantic_score += score

        # ThÃªm Ä‘iá»ƒm sá»‘ ngá»¯ nghÄ©a vÃ o káº¿t quáº£
        result["semantic_scores"] = semantic_scores
        result["semantic_total_score"] = total_semantic_score

        # Káº¿t há»£p Ä‘iá»ƒm sá»‘ ngá»¯ nghÄ©a vá»›i Ä‘iá»ƒm sá»‘ hiá»‡n táº¡i
        current_score = result.get("total_score", 0)
        combined_score = current_score * 0.7 + total_semantic_score * 0.3

        # Cáº­p nháº­t Ä‘iá»ƒm sá»‘
        result["original_score"] = current_score
        result["total_score"] = combined_score

    # Sáº¯p xáº¿p láº¡i káº¿t quáº£ theo Ä‘iá»ƒm sá»‘ má»›i
    results.sort(key=lambda x: x.get("total_score", 0), reverse=True)

    return results

class SemanticEntityMatching:
    """Handle semantic entity matching for GraphRAG agent"""
    
    def __init__(self):
        self._logger = logging.getLogger('agent.graphrag.semantic')
        
    def match_entities(self, text: str, entity_type: str) -> List[Dict[str, Any]]:
        """Match entities in text using semantic search"""
        try:
            log_info(f"ðŸ” TÃ¬m kiáº¿m thá»±c thá»ƒ loáº¡i {entity_type} trong: '{text}'")
            
            # Generate query based on entity type
            query = self._generate_entity_query(entity_type, text)
            if not query:
                return []
                
            # Execute query
            results = execute_query(query)
            
            log_info(f"âœ… TÃ¬m tháº¥y {len(results)} thá»±c thá»ƒ {entity_type}")
            return results
            
        except Exception as e:
            log_error(f"âŒ Lá»—i khi tÃ¬m kiáº¿m thá»±c thá»ƒ: {str(e)}")
            return []
            
    def match_product_entities(self, text: str) -> List[Dict[str, Any]]:
        """Match product entities in text"""
        return self.match_entities(text, "product")
        
    def match_category_entities(self, text: str) -> List[Dict[str, Any]]:
        """Match category entities in text"""
        return self.match_entities(text, "category")
        
    def match_store_entities(self, text: str) -> List[Dict[str, Any]]:
        """Match store entities in text"""
        return self.match_entities(text, "store")
        
    def _generate_entity_query(self, entity_type: str, text: str) -> Optional[str]:
        """Generate query based on entity type"""
        if entity_type == "product":
            return self._generate_product_query(text)
        elif entity_type == "category":
            return self._generate_category_query(text)
        elif entity_type == "store":
            return self._generate_store_query(text)
        else:
            return None
            
    def _generate_product_query(self, text: str) -> str:
        """Generate product query"""
        return f"""
        MATCH (p:Product)-[:BELONGS_TO_CATEGORY]->(c:Category)
        WHERE p.name =~ "(?i).*{text}.*" OR p.descriptions =~ "(?i).*{text}.*"
        RETURN p.id as product_id, p.name as product_name, p.descriptions as product_description,
               c.id as category_id, c.name_cat as category_name, c.description as category_description
        ORDER BY p.name
        LIMIT 10
        """
        
    def _generate_category_query(self, text: str) -> str:
        """Generate category query"""
        return f"""
        MATCH (c:Category)
        WHERE c.name_cat =~ "(?i).*{text}.*" OR c.description =~ "(?i).*{text}.*"
        RETURN c.id as category_id, c.name_cat as category_name, c.description as category_description
        ORDER BY c.name_cat
        LIMIT 10
        """
        
    def _generate_store_query(self, text: str) -> str:
        """Generate store query"""
        return f"""
        MATCH (s:Store)
        WHERE s.name =~ "(?i).*{text}.*" OR s.address =~ "(?i).*{text}.*"
        RETURN s.id as store_id, s.name as store_name, s.address as store_address,
               s.latitude as latitude, s.longitude as longitude
        ORDER BY s.name
        LIMIT 10
        """
