"""
Module x·ª≠ l√Ω n√¢ng cao cho vi·ªác suy lu·∫≠n √Ω ƒë·ªãnh t·ª´ c√¢u h·ªèi ng∆∞·ªùi d√πng
H·ªó tr·ª£ nhi·ªÅu lo·∫°i truy v·∫•n kh√°c nhau: s·∫£n ph·∫©m, c·ª≠a h√†ng, ƒë∆°n h√†ng, danh m·ª•c
ƒê√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ x√°c th·ª±c th√¥ng tin t·ª´ Neo4j
"""
import json
import re
from typing import Dict, List, Any, Optional, Tuple, Union

from ...utils.logger import log_info, log_error
from ...llm_clients.gemini_client import gemini_client
from ...utils.llm_counter import count_llm_call
from .prompt_templates_updated import INTENT_INFERENCE_TEMPLATE
from ...utils.vietnamese_to_english_mapping import translate_vietnamese_to_english, translate_english_to_vietnamese
from .database_validator import DatabaseValidator

# ƒê·ªãnh nghƒ©a c√°c lo·∫°i √Ω ƒë·ªãnh
INTENT_TYPES = {
    "PRODUCT_SEARCH": "t√¨m ki·∫øm s·∫£n ph·∫©m",
    "PRODUCT_INFO": "th√¥ng tin s·∫£n ph·∫©m",
    "CATEGORY_SEARCH": "t√¨m ki·∫øm danh m·ª•c",
    "CATEGORY_INFO": "th√¥ng tin danh m·ª•c",
    "STORE_INFO": "th√¥ng tin c·ª≠a h√†ng",
    "ORDER_INFO": "th√¥ng tin ƒë∆°n h√†ng",
    "ORDER_HISTORY": "l·ªãch s·ª≠ ƒë∆°n h√†ng",
    "RECOMMENDATION": "g·ª£i √Ω s·∫£n ph·∫©m",
    "GREETING": "ch√†o h·ªèi",
    "GENERAL_QUERY": "c√¢u h·ªèi chung"
}

# T·ª´ kh√≥a ƒë·ªÉ ph√¢n lo·∫°i √Ω ƒë·ªãnh
INTENT_KEYWORDS = {
    INTENT_TYPES["PRODUCT_SEARCH"]: [
        "t√¨m", "ki·∫øm", "c√≥", "b√°n", "s·∫£n ph·∫©m", "ƒë·ªì u·ªëng", "th·ª©c u·ªëng", "n∆∞·ªõc", "c√† ph√™", "tr√†", "tr√† s·ªØa", "sinh t·ªë"
    ],
    INTENT_TYPES["PRODUCT_INFO"]: [
        "th√¥ng tin", "chi ti·∫øt", "m√¥ t·∫£", "gi√°", "calo", "ƒë∆∞·ªùng", "caffeine", "th√†nh ph·∫ßn"
    ],
    INTENT_TYPES["CATEGORY_SEARCH"]: [
        "danh m·ª•c", "lo·∫°i", "nh√≥m", "ph√¢n lo·∫°i"
    ],
    INTENT_TYPES["CATEGORY_INFO"]: [
        "danh m·ª•c", "lo·∫°i", "nh√≥m", "th√¥ng tin danh m·ª•c"
    ],
    INTENT_TYPES["STORE_INFO"]: [
        "c·ª≠a h√†ng", "chi nh√°nh", "ƒë·ªãa ch·ªâ", "v·ªã tr√≠", "m·ªü c·ª≠a", "ƒë√≥ng c·ª≠a", "gi·ªù", "ƒë·ªãa ƒëi·ªÉm"
    ],
    INTENT_TYPES["ORDER_INFO"]: [
        "ƒë∆°n h√†ng", "ƒë·∫∑t h√†ng", "mua", "thanh to√°n", "h√≥a ƒë∆°n", "ƒë∆°n", "tr·∫°ng th√°i ƒë∆°n"
    ],
    INTENT_TYPES["ORDER_HISTORY"]: [
        "l·ªãch s·ª≠", "ƒë∆°n h√†ng c≈©", "mua tr∆∞·ªõc ƒë√¢y", "ƒë√£ mua", "ƒë√£ ƒë·∫∑t"
    ],
    INTENT_TYPES["RECOMMENDATION"]: [
        "g·ª£i √Ω", "ƒë·ªÅ xu·∫•t", "recommend", "n√™n u·ªëng", "ph√π h·ª£p", "th√≠ch h·ª£p", "n√™n th·ª≠"
    ],
    INTENT_TYPES["GREETING"]: [
        "xin ch√†o", "ch√†o", "hello", "hi", "hey", "t·∫°m bi·ªát", "goodbye"
    ]
}

# T·ª´ kh√≥a ti·∫øng Anh cho c√°c lo·∫°i ƒë·ªì u·ªëng
ENGLISH_BEVERAGE_KEYWORDS = {
    "coffee": ["coffee", "brewed coffee", "espresso", "latte", "cappuccino", "americano", "mocha", "macchiato", "flat white", "cold brew"],
    "tea": ["tea", "chai", "matcha", "green tea", "black tea", "oolong", "tazo tea", "shaken tea"],
    "milk tea": ["milk tea", "bubble tea", "boba", "pearl milk tea", "chai tea latte", "green tea latte"],
    "smoothie": ["smoothie", "banana chocolate smoothie", "orange mango banana smoothie", "strawberry banana smoothie"],
    "juice": ["juice", "orange juice", "apple juice", "fruit juice", "fresh juice"],
    "frappuccino": ["frappuccino", "frappe", "blended", "iced blended", "coffee frappuccino", "mocha frappuccino", "caramel frappuccino", "java chip frappuccino"],
    "hot chocolate": ["hot chocolate", "chocolate"],
    "other": ["caramel apple spice", "strawberries & cr√®me", "vanilla bean"]
}

# T·ª´ kh√≥a ti·∫øng Vi·ªát cho c√°c lo·∫°i ƒë·ªì u·ªëng
VIETNAMESE_BEVERAGE_KEYWORDS = {
    "c√† ph√™": ["c√† ph√™", "cafe", "c√† ph√™ phin", "c√† ph√™ espresso", "c√† ph√™ s·ªØa", "c√† ph√™ cappuccino", "c√† ph√™ americano", "c√† ph√™ mocha", "c√† ph√™ macchiato", "c√† ph√™ ƒë√°", "c√† ph√™ ·ªß l·∫°nh"],
    "tr√†": ["tr√†", "ch√®", "tr√† xanh", "tr√† ƒëen", "tr√† √¥ long", "tr√† hoa l√†i", "tr√† earl grey", "tr√† chai", "tr√† matcha", "tr√† th·∫£o m·ªôc", "tr√† ƒë√° l·∫Øc", "tr√† chanh ƒë√° l·∫Øc"],
    "tr√† s·ªØa": ["tr√† s·ªØa", "tr√† s·ªØa tr√¢n ch√¢u", "tr√† chai s·ªØa", "tr√† xanh s·ªØa", "tr√† s·ªØa khoai m√¥n", "tr√† s·ªØa th√°i"],
    "sinh t·ªë": ["sinh t·ªë", "sinh t·ªë chu·ªëi s√¥ c√¥ la", "sinh t·ªë cam xo√†i chu·ªëi", "sinh t·ªë d√¢u chu·ªëi", "sinh t·ªë tr√°i c√¢y", "sinh t·ªë s·ªØa chua"],
    "n∆∞·ªõc √©p": ["n∆∞·ªõc √©p", "n∆∞·ªõc cam", "n∆∞·ªõc t√°o", "n∆∞·ªõc d∆∞a h·∫•u", "n∆∞·ªõc d·ª©a", "n∆∞·ªõc √©p c√† r·ªët", "n∆∞·ªõc √©p h·ªón h·ª£p", "n∆∞·ªõc tr√°i c√¢y", "n∆∞·ªõc √©p t∆∞∆°i"],
    "ƒë√° xay": ["ƒë√° xay", "c√† ph√™ ƒë√° xay", "mocha ƒë√° xay", "caramel ƒë√° xay", "java chip ƒë√° xay", "ƒë·ªì u·ªëng ƒë√° xay"],
    "s√¥ c√¥ la": ["s√¥ c√¥ la n√≥ng", "s√¥ c√¥ la"],
    "kh√°c": ["t√°o caramel gia v·ªã", "kem d√¢u", "kem vani", "soda", "n∆∞·ªõc c√≥ ga", "soda chanh", "soda d√¢u", "soda ƒë√†o", "soda chanh d√¢y"]
}

# Danh s√°ch c√°c danh m·ª•c t·ª´ c∆° s·ªü d·ªØ li·ªáu
CATEGORIES = {
    1: "Classic Espresso Drinks",
    2: "Coffee",
    3: "Frappuccino Blended Coffee",
    4: "Frappuccino Blended Cr√®me",
    5: "Frappuccino Light Blended Coffee",
    6: "Shaken Iced Beverages",
    7: "Signature Espresso Drinks",
    8: "Smoothies",
    9: "Tazo Tea Drinks"
}

# Danh s√°ch c√°c c·ªông ƒë·ªìng s·∫£n ph·∫©m t·ª´ c∆° s·ªü d·ªØ li·ªáu
PRODUCT_COMMUNITIES = {
    0: "Product Community 0",
    1: "Product Community 1",
    2: "Product Community 2",
    3: "Product Community 3",  # Ch·ª©a c√°c s·∫£n ph·∫©m sinh t·ªë
    4: "Product Community 4"   # Ch·ª©a s·∫£n ph·∫©m Brewed Coffee
}

def infer_enhanced_intent(question: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Suy lu·∫≠n √Ω ƒë·ªãnh n√¢ng cao c·ªßa ng∆∞·ªùi d√πng t·ª´ c√¢u h·ªèi v√† ng·ªØ c·∫£nh
    ƒê√£ ƒë∆∞·ª£c c·∫£i ti·∫øn ƒë·ªÉ gi·∫£m s·ªë l·∫ßn g·ªçi LLM kh√¥ng c·∫ßn thi·∫øt v√† c·∫£i thi·ªán vi·ªác tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        context (Dict, optional): Ng·ªØ c·∫£nh b·ªï sung (th√¥ng tin kh√°ch h√†ng, l·ªãch s·ª≠ chat)

    Returns:
        Dict[str, Any]: √ù ƒë·ªãnh ƒë∆∞·ª£c suy lu·∫≠n v·ªõi c√°c th√¥ng tin chi ti·∫øt
    """
    log_info("\n1Ô∏è‚É£ Inferring enhanced user intent...")
    log_info(f"üìù Input question: {question}")

    if context:
        log_info(f"üìù Context provided: {str(context)[:200]}...")

    # T·∫°o intent m·∫∑c ƒë·ªãnh
    default_intent = {
        "intent_type": INTENT_TYPES["GENERAL_QUERY"],
        "intent_text": f"T√¨m ki·∫øm th√¥ng tin v·ªÅ {question}",
        "entities": [],
        "product_names": {
            "vi": [],
            "en": []
        },
        "category_names": [],
        "filters": {},
        "is_store_query": False,
        "is_order_query": False,
        "confidence": 0.5
    }

    try:
        # Ki·ªÉm tra c√¢u h·ªèi tr·ªëng
        if not question or question.strip() == "":
            log_error("Empty question provided to intent inference")
            return default_intent

        # B∆∞·ªõc 1: Ph√¢n lo·∫°i √Ω ƒë·ªãnh d·ª±a tr√™n t·ª´ kh√≥a
        intent_type, confidence = _classify_intent_by_keywords(question)

        # B∆∞·ªõc 2: Tr√≠ch xu·∫•t th√¥ng tin s·∫£n ph·∫©m v√† danh m·ª•c
        product_names = _extract_product_names(question)
        category_names = _extract_category_names(question)

        # B∆∞·ªõc 2.1: X√°c th·ª±c th√¥ng tin t·ª´ Neo4j
        validated_product_names = DatabaseValidator.validate_product_names(product_names)
        validated_category_names = DatabaseValidator.validate_category_names(category_names)

        # S·ª≠ d·ª•ng th√¥ng tin ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c n·∫øu c√≥, n·∫øu kh√¥ng th√¨ gi·ªØ nguy√™n
        if validated_product_names["vi"] or validated_product_names["en"]:
            product_names = validated_product_names
            log_info(f"Using validated product names: {json.dumps(product_names, ensure_ascii=False)}")

        if validated_category_names:
            category_names = validated_category_names
            log_info(f"Using validated category names: {category_names}")

        # B∆∞·ªõc 3: Tr√≠ch xu·∫•t c√°c b·ªô l·ªçc (filters)
        filters = _extract_filters(question)

        # B∆∞·ªõc 4: Ki·ªÉm tra xem c√≥ ph·∫£i l√† truy v·∫•n v·ªÅ c·ª≠a h√†ng ho·∫∑c ƒë∆°n h√†ng kh√¥ng
        is_store_query = any(keyword in question.lower() for keyword in INTENT_KEYWORDS[INTENT_TYPES["STORE_INFO"]])
        is_order_query = any(keyword in question.lower() for keyword in INTENT_KEYWORDS[INTENT_TYPES["ORDER_INFO"]]) or \
                         any(keyword in question.lower() for keyword in INTENT_KEYWORDS[INTENT_TYPES["ORDER_HISTORY"]])

        # B∆∞·ªõc 5: T·∫°o intent_text d·ª±a tr√™n th√¥ng tin ƒë√£ tr√≠ch xu·∫•t
        # N·∫øu c√≥ t√™n s·∫£n ph·∫©m ho·∫∑c danh m·ª•c, t·∫°o intent_text m√† kh√¥ng c·∫ßn g·ªçi LLM
        intent_text = ""
        should_call_llm = True

        # Ki·ªÉm tra xem c√≥ ph·∫£i l√† truy v·∫•n v·ªÅ danh m·ª•c kh√¥ng
        is_category_query = False
        if category_names:
            category_keywords = [
                "danh m·ª•c", "category", "lo·∫°i", "nh√≥m", "type", "group",
                "s·∫£n ph·∫©m trong", "products in", "thu·ªôc v·ªÅ", "belongs to",
                "c√≥ nh·ªØng g√¨", "what are", "c√≥ nh·ªØng s·∫£n ph·∫©m n√†o", "what products"
            ]
            is_category_query = any(keyword in question.lower() for keyword in category_keywords)
            log_info(f"Is category query: {is_category_query}")

        if is_category_query and category_names:
            # T·∫°o intent_text cho truy v·∫•n v·ªÅ danh m·ª•c
            intent_text = f"Ng∆∞·ªùi d√πng mu·ªën bi·∫øt danh m·ª•c {category_names[0]} c√≥ nh·ªØng s·∫£n ph·∫©m g√¨."
            should_call_llm = False

        elif product_names["vi"] or product_names["en"]:
            # L·∫•y t√™n s·∫£n ph·∫©m d√†i nh·∫•t (th∆∞·ªùng l√† t√™n ƒë·∫ßy ƒë·ªß nh·∫•t)
            all_product_names = product_names["vi"] + product_names["en"]
            if all_product_names:
                longest_product_name = max(all_product_names, key=len)
                intent_text = f"Ng∆∞·ªùi d√πng mu·ªën bi·∫øt th√¥ng tin v·ªÅ {longest_product_name}."
                should_call_llm = False

        elif category_names and not is_category_query:
            # L·∫•y t√™n danh m·ª•c ƒë·∫ßu ti√™n
            intent_text = f"Ng∆∞·ªùi d√πng mu·ªën bi·∫øt th√¥ng tin v·ªÅ danh m·ª•c {category_names[0]}."
            should_call_llm = False

        elif is_store_query:
            intent_text = "Ng∆∞·ªùi d√πng mu·ªën bi·∫øt th√¥ng tin v·ªÅ c·ª≠a h√†ng."
            should_call_llm = False

        elif is_order_query:
            intent_text = "Ng∆∞·ªùi d√πng mu·ªën bi·∫øt th√¥ng tin v·ªÅ ƒë∆°n h√†ng c·ªßa h·ªç."
            should_call_llm = False

        # N·∫øu kh√¥ng th·ªÉ t·∫°o intent_text t·ª´ th√¥ng tin ƒë√£ tr√≠ch xu·∫•t, g·ªçi LLM
        if should_call_llm:
            intent_text = _get_intent_text_from_llm(question, context)

        # T·∫°o k·∫øt qu·∫£ cu·ªëi c√πng
        result = {
            "intent_type": intent_type,
            "intent_text": intent_text,
            "entities": [],  # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t sau n·∫øu c·∫ßn
            "product_names": product_names,
            "category_names": category_names,
            "filters": filters,
            "is_store_query": is_store_query,
            "is_order_query": is_order_query,
            "confidence": confidence
        }

        log_info(f"üß† Enhanced intent inference result: {json.dumps(result, ensure_ascii=False)}")
        return result

    except Exception as e:
        log_error(f"Error in enhanced intent inference: {str(e)}")
        return default_intent

def _classify_intent_by_keywords(question: str) -> Tuple[str, float]:
    """
    Ph√¢n lo·∫°i √Ω ƒë·ªãnh d·ª±a tr√™n t·ª´ kh√≥a trong c√¢u h·ªèi

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng

    Returns:
        Tuple[str, float]: Lo·∫°i √Ω ƒë·ªãnh v√† ƒë·ªô tin c·∫≠y
    """
    question_lower = question.lower()

    # ƒê·∫øm s·ªë t·ª´ kh√≥a kh·ªõp cho m·ªói lo·∫°i √Ω ƒë·ªãnh
    intent_scores = {}
    for intent_type, keywords in INTENT_KEYWORDS.items():
        score = sum(1 for keyword in keywords if keyword in question_lower)
        intent_scores[intent_type] = score

    # T√¨m lo·∫°i √Ω ƒë·ªãnh c√≥ ƒëi·ªÉm cao nh·∫•t
    max_score = max(intent_scores.values()) if intent_scores else 0
    if max_score == 0:
        return INTENT_TYPES["GENERAL_QUERY"], 0.5

    # T√¨m t·∫•t c·∫£ c√°c lo·∫°i √Ω ƒë·ªãnh c√≥ ƒëi·ªÉm cao nh·∫•t
    top_intents = [intent for intent, score in intent_scores.items() if score == max_score]

    # ∆Øu ti√™n theo th·ª© t·ª±: s·∫£n ph·∫©m > danh m·ª•c > c·ª≠a h√†ng > ƒë∆°n h√†ng > chung
    priority_order = [
        INTENT_TYPES["PRODUCT_SEARCH"], INTENT_TYPES["PRODUCT_INFO"],
        INTENT_TYPES["CATEGORY_SEARCH"], INTENT_TYPES["CATEGORY_INFO"],
        INTENT_TYPES["RECOMMENDATION"],
        INTENT_TYPES["STORE_INFO"],
        INTENT_TYPES["ORDER_INFO"], INTENT_TYPES["ORDER_HISTORY"],
        INTENT_TYPES["GREETING"],
        INTENT_TYPES["GENERAL_QUERY"]
    ]

    for intent in priority_order:
        if intent in top_intents:
            # T√≠nh ƒë·ªô tin c·∫≠y d·ª±a tr√™n s·ªë t·ª´ kh√≥a kh·ªõp
            confidence = min(0.5 + (max_score * 0.1), 0.9)  # Gi·ªõi h·∫°n trong kho·∫£ng 0.5-0.9
            return intent, confidence

    return INTENT_TYPES["GENERAL_QUERY"], 0.5

def _extract_product_names(question: str) -> Dict[str, List[str]]:
    """
    Tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m t·ª´ c√¢u h·ªèi, bao g·ªìm c·∫£ t√™n ti·∫øng Vi·ªát v√† ti·∫øng Anh
    ƒê√£ ƒë∆∞·ª£c c·∫£i ti·∫øn ƒë·ªÉ tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c h∆°n

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng

    Returns:
        Dict[str, List[str]]: Danh s√°ch t√™n s·∫£n ph·∫©m theo ng√¥n ng·ªØ
    """
    result = {
        "vi": [],
        "en": []
    }

    # Chu·∫©n b·ªã c√¢u h·ªèi ƒë·ªÉ t√¨m ki·∫øm
    question_lower = question.lower()

    # B∆∞·ªõc 0: Tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m t·ª´ c√°c t·ª´ kh√≥a ch·ªâ s·∫£n ph·∫©m
    product_indicators = ["v·ªÅ", "m√¥ t·∫£", "th√¥ng tin", "gi·ªõi thi·ªáu", "cho t√¥i bi·∫øt v·ªÅ", "cho t√¥i", "t√¥i mu·ªën"]

    for indicator in product_indicators:
        if indicator in question_lower:
            # T√¨m v·ªã tr√≠ c·ªßa t·ª´ kh√≥a ch·ªâ s·∫£n ph·∫©m
            pos = question_lower.find(indicator) + len(indicator)
            if pos < len(question_lower):
                # L·∫•y ph·∫ßn c√≤n l·∫°i c·ªßa c√¢u l√†m t√™n s·∫£n ph·∫©m ti·ªÅm nƒÉng
                remaining_text = question_lower[pos:].strip()
                if remaining_text:
                    # Ki·ªÉm tra xem ph·∫ßn c√≤n l·∫°i c√≥ ph·∫£i l√† t√™n s·∫£n ph·∫©m kh√¥ng
                    # N·∫øu c√≥ t·ª´ kh√≥a ch·ªâ s·∫£n ph·∫©m kh√°c, c·∫Øt t·∫°i ƒë√≥
                    for other_indicator in product_indicators:
                        if other_indicator in remaining_text:
                            remaining_text = remaining_text.split(other_indicator)[0].strip()

                    # Th√™m v√†o danh s√°ch t√™n s·∫£n ph·∫©m ti·ªÅm nƒÉng
                    potential_product = remaining_text

                    # X√°c ƒë·ªãnh ng√¥n ng·ªØ c·ªßa t√™n s·∫£n ph·∫©m
                    if any(char in "√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë" for char in potential_product):
                        if potential_product not in result["vi"]:
                            result["vi"].append(potential_product)
                    else:
                        if potential_product not in result["en"]:
                            result["en"].append(potential_product)

                    # N·∫øu ƒë√£ t√¨m th·∫•y t√™n s·∫£n ph·∫©m, kh√¥ng c·∫ßn t√¨m ti·∫øp
                    if result["vi"] or result["en"]:
                        break

    # B∆∞·ªõc 1: T√¨m ki·∫øm c√°c c·ª•m t·ª´ ho√†n ch·ªânh
    # Danh s√°ch c√°c c·ª•m t·ª´ c·ª• th·ªÉ ƒë·ªÉ t√¨m ki·∫øm
    specific_product_patterns = [
        # C√† ph√™
        (r"c√† ph√™\s+(?:s·ªØa|ƒëen|ƒë√°|n√≥ng|phin|espresso|latte|mocha|americano|cappuccino)(?:\s+(?:ƒë√°|n√≥ng|√≠t ƒë∆∞·ªùng|kh√¥ng ƒë∆∞·ªùng|√≠t s·ªØa))*", "vi"),
        (r"(?:brewed|iced)\s+coffee(?:\s+with\s+(?:milk|sugar|cream))?", "en"),
        (r"(?:caff√®|caffe)\s+(?:latte|mocha|americano)", "en"),
        (r"(?:vanilla|caramel)\s+latte", "en"),
        (r"(?:cappuccino|espresso|macchiato)", "en"),
        (r"(?:white\s+chocolate\s+mocha)", "en"),

        # Tr√†
        (r"tr√†\s+(?:xanh|ƒëen|s·ªØa|ƒë√†o|v·∫£i|chanh|hoa l√†i|√¥ long|matcha)(?:\s+(?:ƒë√°|n√≥ng|√≠t ƒë∆∞·ªùng|kh√¥ng ƒë∆∞·ªùng))*", "vi"),
        (r"(?:green|black|oolong|jasmine|earl grey|chai)\s+tea", "en"),
        (r"(?:tazo\s+chai|tazo\s+green)\s+tea\s+latte", "en"),
        (r"(?:shaken\s+iced\s+tazo)\s+tea(?:\s+lemonade)?", "en"),
        (r"shaken\s+iced\s+tea", "en"),

        # Sinh t·ªë
        (r"sinh t·ªë\s+(?:xo√†i|d√¢u|chu·ªëi|b∆°|d·ª´a|vi·ªát qu·∫•t|cam)(?:\s+(?:s·ªØa chua|s·ªØa|ƒë√°|√≠t ƒë∆∞·ªùng))*", "vi"),
        (r"(?:banana\s+chocolate|orange\s+mango\s+banana|strawberry\s+banana)\s+smoothie", "en"),
        (r"(?:mango|strawberry|banana|avocado|coconut|blueberry|orange)\s+smoothie", "en"),

        # ƒê√° xay
        (r"(?:c√† ph√™|mocha|caramel|java chip|tr√† xanh)\s+ƒë√° xay", "vi"),
        (r"(?:coffee|mocha|caramel|java chip)\s+(?:frappuccino|frappe)", "en"),

        # Tr√† s·ªØa
        (r"tr√† s·ªØa\s+(?:tr√¢n ch√¢u|khoai m√¥n|th√°i|matcha|socola)(?:\s+(?:ƒë√°|n√≥ng|√≠t ƒë∆∞·ªùng|kh√¥ng ƒë∆∞·ªùng))*", "vi"),
        (r"(?:bubble|boba|pearl milk|taro milk|thai milk)\s+tea", "en"),

        # S√¥ c√¥ la
        (r"s√¥ c√¥ la\s+(?:n√≥ng|ƒë√°)", "vi"),
        (r"hot\s+chocolate", "en")
    ]

    # T√¨m ki·∫øm c√°c c·ª•m t·ª´ c·ª• th·ªÉ
    for pattern, lang in specific_product_patterns:
        matches = re.findall(pattern, question_lower)
        for match in matches:
            if match and match not in result[lang]:
                result[lang].append(match)

    # B∆∞·ªõc 2: N·∫øu kh√¥ng t√¨m th·∫•y c·ª•m t·ª´ c·ª• th·ªÉ, t√¨m ki·∫øm t·ª´ kh√≥a chung
    if not result["vi"] and not result["en"]:
        # T√¨m ki·∫øm t√™n s·∫£n ph·∫©m ti·∫øng Vi·ªát
        for beverage_type, keywords in VIETNAMESE_BEVERAGE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in question_lower and beverage_type not in result["vi"]:
                    result["vi"].append(beverage_type)
                    break

        # T√¨m ki·∫øm t√™n s·∫£n ph·∫©m ti·∫øng Anh
        for beverage_type, keywords in ENGLISH_BEVERAGE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in question_lower and beverage_type not in result["en"]:
                    result["en"].append(beverage_type)
                    break

    # B∆∞·ªõc 3: Ki·ªÉm tra c√°c s·∫£n ph·∫©m c·ª• th·ªÉ t·ª´ c∆° s·ªü d·ªØ li·ªáu
    specific_products = {
        "banana chocolate smoothie": "sinh t·ªë chu·ªëi s√¥ c√¥ la",
        "orange mango banana smoothie": "sinh t·ªë cam xo√†i chu·ªëi",
        "strawberry banana smoothie": "sinh t·ªë d√¢u chu·ªëi",
        "brewed coffee": "c√† ph√™ phin",
        "caff√® latte": "c√† ph√™ s·ªØa",
        "caff√® mocha": "c√† ph√™ mocha",
        "vanilla latte": "c√† ph√™ s·ªØa vani",
        "caff√® americano": "c√† ph√™ americano",
        "cappuccino": "c√† ph√™ cappuccino",
        "espresso": "c√† ph√™ espresso",
        "caramel macchiato": "c√† ph√™ caramel macchiato",
        "white chocolate mocha": "c√† ph√™ mocha s√¥ c√¥ la tr·∫Øng",
        "hot chocolate": "s√¥ c√¥ la n√≥ng",
        "tazo chai tea latte": "tr√† chai s·ªØa",
        "tazo green tea latte": "tr√† xanh s·ªØa",
        "shaken iced tea": "tr√† ƒë√° l·∫Øc"
    }

    for en_name, vi_name in specific_products.items():
        if en_name in question_lower and en_name not in result["en"]:
            result["en"].append(en_name)
        if vi_name in question_lower and vi_name not in result["vi"]:
            result["vi"].append(vi_name)

    # B∆∞·ªõc 4: Lo·∫°i b·ªè c√°c t√™n s·∫£n ph·∫©m tr√πng l·∫∑p ho·∫∑c l√† ph·∫ßn con c·ªßa t√™n kh√°c
    # V√≠ d·ª•: n·∫øu c√≥ "c√† ph√™ s·ªØa ƒë√°" th√¨ kh√¥ng c·∫ßn "c√† ph√™", "c√† ph√™ s·ªØa", "c√† ph√™ ƒë√°"
    result["vi"] = _remove_redundant_product_names(result["vi"])
    result["en"] = _remove_redundant_product_names(result["en"])

    return result

def _remove_redundant_product_names(product_names: List[str]) -> List[str]:
    """
    Lo·∫°i b·ªè c√°c t√™n s·∫£n ph·∫©m tr√πng l·∫∑p ho·∫∑c l√† ph·∫ßn con c·ªßa t√™n kh√°c

    Args:
        product_names (List[str]): Danh s√°ch t√™n s·∫£n ph·∫©m

    Returns:
        List[str]: Danh s√°ch t√™n s·∫£n ph·∫©m ƒë√£ ƒë∆∞·ª£c l·ªçc
    """
    if not product_names:
        return []

    # S·∫Øp x·∫øp t√™n s·∫£n ph·∫©m theo ƒë·ªô d√†i gi·∫£m d·∫ßn
    sorted_names = sorted(product_names, key=len, reverse=True)

    # Danh s√°ch k·∫øt qu·∫£
    result = []

    # Th√™m t√™n s·∫£n ph·∫©m d√†i nh·∫•t v√†o k·∫øt qu·∫£
    result.append(sorted_names[0])

    # Ki·ªÉm tra c√°c t√™n s·∫£n ph·∫©m c√≤n l·∫°i
    for name in sorted_names[1:]:
        # Ki·ªÉm tra xem t√™n s·∫£n ph·∫©m c√≥ l√† ph·∫ßn con c·ªßa t√™n n√†o ƒë√≥ trong k·∫øt qu·∫£ kh√¥ng
        is_substring = False
        for existing_name in result:
            if name in existing_name:
                is_substring = True
                break

        # N·∫øu kh√¥ng ph·∫£i l√† ph·∫ßn con, th√™m v√†o k·∫øt qu·∫£
        if not is_substring:
            result.append(name)

    return result

def _extract_category_names(question: str) -> List[str]:
    """
    Tr√≠ch xu·∫•t t√™n danh m·ª•c t·ª´ c√¢u h·ªèi
    ƒê√£ ƒë∆∞·ª£c c·∫£i ti·∫øn ƒë·ªÉ tr√≠ch xu·∫•t t√™n danh m·ª•c ch√≠nh x√°c h∆°n v√† x√°c th·ª±c v·ªõi Neo4j

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng

    Returns:
        List[str]: Danh s√°ch t√™n danh m·ª•c
    """
    # Chu·∫©n b·ªã c√¢u h·ªèi ƒë·ªÉ t√¨m ki·∫øm
    question_lower = question.lower()

    # T√¨m ki·∫øm c√°c m·∫´u danh m·ª•c c·ª• th·ªÉ
    category_patterns = [
        r"danh m·ª•c\s+(.*?)(?:\s+c√≥|$)",
        r"lo·∫°i\s+(.*?)(?:\s+c√≥|$)",
        r"nh√≥m\s+(.*?)(?:\s+c√≥|$)",
        r"category\s+(.*?)(?:\s+has|$)"
    ]

    extracted_categories = []
    for pattern in category_patterns:
        matches = re.findall(pattern, question_lower)
        if matches:
            for match in matches:
                if match.strip() and match.strip() not in extracted_categories:
                    extracted_categories.append(match.strip())

    # N·∫øu t√¨m th·∫•y danh m·ª•c t·ª´ m·∫´u c·ª• th·ªÉ, x√°c th·ª±c v√† tr·∫£ v·ªÅ
    if extracted_categories:
        # X√°c th·ª±c c√°c danh m·ª•c ƒë√£ tr√≠ch xu·∫•t
        validated_categories, confidence = DatabaseValidator.extract_category_from_text(question)
        if validated_categories:
            return validated_categories

    # N·∫øu kh√¥ng t√¨m th·∫•y t·ª´ m·∫´u c·ª• th·ªÉ, ti·∫øp t·ª•c v·ªõi ph∆∞∆°ng ph√°p t·ª´ kh√≥a
    categories = []

    # √Ånh x·∫° t·ª´ kh√≥a ti·∫øng Vi·ªát sang danh m·ª•c trong c∆° s·ªü d·ªØ li·ªáu
    category_keywords = {
        "Classic Espresso Drinks": ["c√† ph√™ espresso", "c√† ph√™ s·ªØa", "c√† ph√™ mocha", "c√† ph√™ vani", "c√† ph√™ americano", "cappuccino", "espresso", "latte", "mocha"],
        "Coffee": ["c√† ph√™ phin", "c√† ph√™ ƒëen", "c√† ph√™ ƒë√°", "brewed coffee"],
        "Frappuccino Blended Coffee": ["c√† ph√™ ƒë√° xay", "coffee frappuccino", "mocha frappuccino", "caramel frappuccino", "java chip frappuccino"],
        "Frappuccino Blended Cr√®me": ["ƒë√° xay kem", "kem ƒë√° xay", "strawberries & cr√®me", "vanilla bean"],
        "Frappuccino Light Blended Coffee": ["c√† ph√™ ƒë√° xay √≠t b√©o", "coffee light frappuccino", "mocha light frappuccino", "caramel light frappuccino"],
        "Shaken Iced Beverages": ["ƒë·ªì u·ªëng ƒë√° l·∫Øc", "tr√† ƒë√° l·∫Øc", "tr√† chanh ƒë√° l·∫Øc", "shaken iced tazo tea", "shaken iced tazo tea lemonade"],
        "Signature Espresso Drinks": ["c√† ph√™ ƒë·∫∑c bi·ªát", "c√† ph√™ caramel macchiato", "c√† ph√™ mocha s√¥ c√¥ la tr·∫Øng", "caramel macchiato", "white chocolate mocha"],
        "Smoothies": ["sinh t·ªë", "sinh t·ªë chu·ªëi s√¥ c√¥ la", "sinh t·ªë cam xo√†i chu·ªëi", "sinh t·ªë d√¢u chu·ªëi", "banana chocolate smoothie", "orange mango banana smoothie", "strawberry banana smoothie"],
        "Tazo Tea Drinks": ["tr√†", "tr√† chai s·ªØa", "tr√† xanh s·ªØa", "tr√† ƒë√†o", "tr√† v·∫£i", "tr√† chanh", "tazo chai tea latte", "tazo green tea latte"]
    }

    # Ki·ªÉm tra t·ª´ng danh m·ª•c
    for category_name, keywords in category_keywords.items():
        for keyword in keywords:
            if keyword in question_lower:
                # Th√™m t√™n danh m·ª•c ti·∫øng Anh
                if category_name not in categories:
                    categories.append(category_name)

                # Th√™m t√™n danh m·ª•c ti·∫øng Vi·ªát t∆∞∆°ng ·ª©ng
                vi_category_name = _get_vietnamese_category_name(category_name)
                if vi_category_name and vi_category_name not in categories:
                    categories.append(vi_category_name)

                break

    # N·∫øu kh√¥ng t√¨m th·∫•y danh m·ª•c c·ª• th·ªÉ, ki·ªÉm tra c√°c t·ª´ kh√≥a chung
    if not categories:
        common_keywords = {
            "c√† ph√™": ["Classic Espresso Drinks", "Coffee", "ƒê·ªì u·ªëng c√† ph√™"],
            "coffee": ["Classic Espresso Drinks", "Coffee", "ƒê·ªì u·ªëng c√† ph√™"],
            "tr√†": ["Tazo Tea Drinks", "ƒê·ªì u·ªëng tr√†"],
            "tea": ["Tazo Tea Drinks", "ƒê·ªì u·ªëng tr√†"],
            "sinh t·ªë": ["Smoothies", "Sinh t·ªë"],
            "smoothie": ["Smoothies", "Sinh t·ªë"],
            "ƒë√° xay": ["Frappuccino Blended Coffee", "Frappuccino Blended Cr√®me", "ƒê·ªì u·ªëng ƒë√° xay"],
            "frappuccino": ["Frappuccino Blended Coffee", "Frappuccino Blended Cr√®me", "ƒê·ªì u·ªëng ƒë√° xay"]
        }

        for keyword, category_list in common_keywords.items():
            if keyword in question_lower:
                for category_name in category_list:
                    if category_name not in categories:
                        categories.append(category_name)

    # X√°c th·ª±c danh m·ª•c v·ªõi Neo4j
    if categories:
        validated_categories = DatabaseValidator.validate_category_names(categories)
        if validated_categories:
            return validated_categories

    return categories

def _get_vietnamese_category_name(category_name: str) -> str:
    """
    Chuy·ªÉn ƒë·ªïi t√™n danh m·ª•c t·ª´ ti·∫øng Anh sang ti·∫øng Vi·ªát

    Args:
        category_name (str): T√™n danh m·ª•c ti·∫øng Anh

    Returns:
        str: T√™n danh m·ª•c ti·∫øng Vi·ªát
    """
    category_mapping = {
        "Classic Espresso Drinks": "ƒê·ªì u·ªëng c√† ph√™ espresso c·ªï ƒëi·ªÉn",
        "Coffee": "C√† ph√™",
        "Frappuccino Blended Coffee": "C√† ph√™ ƒë√° xay",
        "Frappuccino Blended Cr√®me": "Kem ƒë√° xay",
        "Frappuccino Light Blended Coffee": "C√† ph√™ ƒë√° xay √≠t b√©o",
        "Shaken Iced Beverages": "ƒê·ªì u·ªëng ƒë√° l·∫Øc",
        "Signature Espresso Drinks": "ƒê·ªì u·ªëng c√† ph√™ ƒë·∫∑c bi·ªát",
        "Smoothies": "Sinh t·ªë",
        "Tazo Tea Drinks": "ƒê·ªì u·ªëng tr√†"
    }

    return category_mapping.get(category_name, "")

def _extract_filters(question: str) -> Dict[str, Any]:
    """
    Tr√≠ch xu·∫•t c√°c b·ªô l·ªçc t·ª´ c√¢u h·ªèi

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng

    Returns:
        Dict[str, Any]: C√°c b·ªô l·ªçc ƒë∆∞·ª£c tr√≠ch xu·∫•t
    """
    filters = {}
    question_lower = question.lower()

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ gi√°
    price_patterns = [
        r"gi√°\s+d∆∞·ªõi\s+(\d+)[k\s]",
        r"d∆∞·ªõi\s+(\d+)[k\s]",
        r"r·∫ª\s+h∆°n\s+(\d+)[k\s]",
        r"kh√¥ng\s+qu√°\s+(\d+)[k\s]",
        r"gi√°\s+kho·∫£ng\s+(\d+)[k\s]",
        r"kho·∫£ng\s+(\d+)[k\s]",
        r"(\d+)k",
        r"(\d+)\s+ngh√¨n"
    ]

    for pattern in price_patterns:
        matches = re.search(pattern, question_lower)
        if matches:
            price = int(matches.group(1)) * 1000  # Chuy·ªÉn ƒë·ªïi k th√†nh ƒë∆°n v·ªã ƒë·ªìng

            # X√°c ƒë·ªãnh lo·∫°i b·ªô l·ªçc gi√°
            if "d∆∞·ªõi" in question_lower or "r·∫ª h∆°n" in question_lower or "kh√¥ng qu√°" in question_lower:
                filters["max_price"] = price
            elif "tr√™n" in question_lower or "ƒë·∫Øt h∆°n" in question_lower or "√≠t nh·∫•t" in question_lower:
                filters["min_price"] = price
            else:
                # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a r√µ r√†ng, s·ª≠ d·ª•ng kho·∫£ng gi√°
                filters["price_range"] = {
                    "min": max(0, price - 10000),
                    "max": price + 10000
                }
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ ƒë∆∞·ªùng
    sugar_patterns = {
        "low": [
            r"√≠t\s+ƒë∆∞·ªùng", r"√≠t\s+ng·ªçt", r"kh√¥ng\s+ƒë∆∞·ªùng", r"kh√¥ng\s+ng·ªçt",
            r"ƒë∆∞·ªùng\s+th·∫•p", r"gi·∫£m\s+ƒë∆∞·ªùng", r"ƒë∆∞·ªùng\s+√≠t"
        ],
        "high": [
            r"nhi·ªÅu\s+ƒë∆∞·ªùng", r"ng·ªçt", r"ƒë∆∞·ªùng\s+nhi·ªÅu", r"ƒë∆∞·ªùng\s+cao"
        ]
    }

    for sugar_level, patterns in sugar_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                if sugar_level == "low":
                    filters["low_sugar"] = True
                else:
                    filters["high_sugar"] = True
                break
        if "low_sugar" in filters or "high_sugar" in filters:
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ caffeine
    caffeine_patterns = {
        "low": [
            r"kh√¥ng\s+caffeine", r"√≠t\s+caffeine", r"caffeine\s+th·∫•p",
            r"gi·∫£m\s+caffeine", r"kh√¥ng\s+mu·ªën\s+t·ªânh\s+t√°o"
        ],
        "high": [
            r"nhi·ªÅu\s+caffeine", r"caffeine\s+cao", r"t·ªânh\s+t√°o",
            r"c·∫ßn\s+t·ªânh\s+t√°o", r"mu·ªën\s+t·ªânh\s+t√°o", r"ƒëang\s+bu·ªìn\s+ng·ªß"
        ]
    }

    for caffeine_level, patterns in caffeine_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                if caffeine_level == "low":
                    filters["low_caffeine"] = True
                else:
                    filters["high_caffeine"] = True
                break
        if "low_caffeine" in filters or "high_caffeine" in filters:
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ calo
    calorie_patterns = {
        "low": [
            r"√≠t\s+calo", r"calo\s+th·∫•p", r"gi·∫£m\s+c√¢n", r"ƒëang\s+ƒÉn\s+ki√™ng",
            r"√≠t\s+b√©o", r"kh√¥ng\s+b√©o", r"ƒëang\s+diet"
        ],
        "high": [
            r"nhi·ªÅu\s+calo", r"calo\s+cao", r"tƒÉng\s+c√¢n", r"c·∫ßn\s+nƒÉng\s+l∆∞·ª£ng"
        ]
    }

    for calorie_level, patterns in calorie_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                if calorie_level == "low":
                    filters["low_calories"] = True
                else:
                    filters["high_calories"] = True
                break
        if "low_calories" in filters or "high_calories" in filters:
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ k√≠ch th∆∞·ªõc
    size_patterns = {
        "small": [r"nh·ªè", r"short", r"size\s+s"],
        "medium": [r"v·ª´a", r"tall", r"size\s+m"],
        "large": [r"l·ªõn", r"grande", r"size\s+l"],
        "extra_large": [r"r·∫•t\s+l·ªõn", r"venti", r"size\s+xl"]
    }

    for size, patterns in size_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                filters["size"] = size
                break
        if "size" in filters:
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ lo·∫°i s·ªØa
    milk_patterns = {
        "nonfat": [r"s·ªØa\s+kh√¥ng\s+b√©o", r"s·ªØa\s+t√°ch\s+b√©o", r"nonfat\s+milk", r"skim\s+milk"],
        "2%": [r"s·ªØa\s+2%", r"2%\s+milk"],
        "whole": [r"s·ªØa\s+nguy√™n\s+kem", r"s·ªØa\s+b√©o", r"whole\s+milk"],
        "soy": [r"s·ªØa\s+ƒë·∫≠u\s+n√†nh", r"soymilk", r"soy\s+milk"],
        "almond": [r"s·ªØa\s+h·∫°nh\s+nh√¢n", r"almond\s+milk"],
        "coconut": [r"s·ªØa\s+d·ª´a", r"coconut\s+milk"]
    }

    for milk_type, patterns in milk_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                filters["milk_type"] = milk_type
                break
        if "milk_type" in filters:
            break

    # Tr√≠ch xu·∫•t th√¥ng tin v·ªÅ nhi·ªát ƒë·ªô
    temp_patterns = {
        "hot": [r"n√≥ng", r"hot"],
        "iced": [r"ƒë√°", r"l·∫°nh", r"iced", r"cold"]
    }

    for temp, patterns in temp_patterns.items():
        for pattern in patterns:
            if re.search(pattern, question_lower):
                filters["temperature"] = temp
                break
        if "temperature" in filters:
            break

    # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát
    if "sinh t·ªë" in question_lower or "smoothie" in question_lower:
        # Sinh t·ªë th∆∞·ªùng kh√¥ng c√≥ caffeine
        filters["low_caffeine"] = True

        # Ki·ªÉm tra c√°c lo·∫°i tr√°i c√¢y
        fruits = {
            "mango": ["xo√†i", "mango"],
            "strawberry": ["d√¢u", "strawberry"],
            "banana": ["chu·ªëi", "banana"],
            "orange": ["cam", "orange"],
            "blueberry": ["vi·ªát qu·∫•t", "blueberry"],
            "avocado": ["b∆°", "avocado"],
            "coconut": ["d·ª´a", "coconut"]
        }

        for fruit_name, keywords in fruits.items():
            for keyword in keywords:
                if keyword in question_lower:
                    if "fruits" not in filters:
                        filters["fruits"] = []
                    filters["fruits"].append(fruit_name)

    # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát cho c√† ph√™
    if "c√† ph√™" in question_lower or "coffee" in question_lower:
        # Ki·ªÉm tra c√°c lo·∫°i c√† ph√™ ƒë·∫∑c bi·ªát
        coffee_types = {
            "espresso": ["espresso"],
            "latte": ["latte", "c√† ph√™ s·ªØa"],
            "mocha": ["mocha"],
            "americano": ["americano"],
            "cappuccino": ["cappuccino"],
            "macchiato": ["macchiato"]
        }

        for coffee_type, keywords in coffee_types.items():
            for keyword in keywords:
                if keyword in question_lower:
                    filters["coffee_type"] = coffee_type
                    break
            if "coffee_type" in filters:
                break

    return filters

@count_llm_call
def _get_intent_text_from_llm(question: str, context: Optional[Dict[str, Any]] = None) -> str:
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ suy lu·∫≠n √Ω ƒë·ªãnh chi ti·∫øt

    Args:
        question (str): C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        context (Dict, optional): Ng·ªØ c·∫£nh b·ªï sung (th√¥ng tin kh√°ch h√†ng, l·ªãch s·ª≠ chat)

    Returns:
        str: √ù ƒë·ªãnh ƒë∆∞·ª£c suy lu·∫≠n d∆∞·ªõi d·∫°ng vƒÉn b·∫£n
    """
    try:
        # Chu·∫©n b·ªã th√¥ng tin ng·ªØ c·∫£nh
        context_info = ""
        if context:
            # Th√™m th√¥ng tin v·ªÅ kh√°ch h√†ng
            if 'customer' in context:
                customer = context['customer']
                customer_info = f"""
Th√¥ng tin kh√°ch h√†ng:
- T√™n: {customer.get('name', 'Kh√¥ng x√°c ƒë·ªãnh')}
- ID: {customer.get('id', 'Kh√¥ng x√°c ƒë·ªãnh')}
"""
                context_info += customer_info

            # Th√™m th√¥ng tin v·ªÅ l·ªãch s·ª≠ ƒë∆°n h√†ng
            if 'order_history' in context and context['order_history']:
                orders = context['order_history']
                order_info = "L·ªãch s·ª≠ ƒë∆°n h√†ng g·∫ßn ƒë√¢y:\n"
                for i, order in enumerate(orders[:3], 1):  # Ch·ªâ l·∫•y 3 ƒë∆°n h√†ng g·∫ßn nh·∫•t
                    order_info += f"- ƒê∆°n h√†ng {i}: {order.get('date', 'Kh√¥ng x√°c ƒë·ªãnh')}, T·ªïng ti·ªÅn: {order.get('total', 'Kh√¥ng x√°c ƒë·ªãnh')}\n"
                context_info += order_info

            # Th√™m th√¥ng tin v·ªÅ l·ªãch s·ª≠ chat
            if 'chat_history' in context and context['chat_history']:
                chat_history = context['chat_history']
                chat_info = "L·ªãch s·ª≠ chat g·∫ßn ƒë√¢y:\n"
                for i, chat in enumerate(chat_history[-3:], 1):  # Ch·ªâ l·∫•y 3 tin nh·∫Øn g·∫ßn nh·∫•t
                    chat_info += f"- Ng∆∞·ªùi d√πng: {chat.get('user_message', '')}\n"
                    chat_info += f"  H·ªá th·ªëng: {chat.get('system_message', '')}\n"
                context_info += chat_info

        # T·∫°o prompt ƒë·ªÉ suy lu·∫≠n √Ω ƒë·ªãnh
        prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch ng√¥n ng·ªØ t·ª± nhi√™n v√† chuy√™n gia v·ªÅ ƒë·ªì u·ªëng. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† suy lu·∫≠n √Ω ƒë·ªãnh th·ª±c s·ª± c·ªßa h·ªç.

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{question}"

{context_info if context_info else ""}

H√£y suy lu·∫≠n √Ω ƒë·ªãnh th·ª±c s·ª± c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n c√¢u h·ªèi c·ªßa h·ªç v√† ng·ªØ c·∫£nh (n·∫øu c√≥). V√≠ d·ª•:
- N·∫øu ng∆∞·ªùi d√πng n√≥i "t√¥i kh√°t" ho·∫∑c "tr·ªùi n√≥ng qu√°", h·ªç ƒëang t√¨m ki·∫øm ƒë·ªì u·ªëng gi·∫£i kh√°t, m√°t l·∫°nh
- N·∫øu ng∆∞·ªùi d√πng n√≥i "t√¥i m·ªát" ho·∫∑c "bu·ªìn ng·ªß qu√°", h·ªç ƒëang t√¨m ki·∫øm ƒë·ªì u·ªëng c√≥ caffeine ƒë·ªÉ t·ªânh t√°o
- N·∫øu ng∆∞·ªùi d√πng ch·ªâ n√≥i t√™n ƒë·ªì u·ªëng nh∆∞ "tr√† s·ªØa", h·ªç ƒëang t√¨m ki·∫øm th√¥ng tin v·ªÅ lo·∫°i ƒë·ªì u·ªëng ƒë√≥
- N·∫øu ng∆∞·ªùi d√πng n√≥i "th·ª©c u·ªëng t·ªët cho s·ª©c kh·ªèe", h·ªç ƒëang t√¨m ki·∫øm ƒë·ªì u·ªëng c√≥ gi√° tr·ªã dinh d∆∞·ª°ng cao
- N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ c·ª≠a h√†ng, h·ªç ƒëang t√¨m ki·∫øm th√¥ng tin v·ªÅ ƒë·ªãa ƒëi·ªÉm, gi·ªù m·ªü c·ª≠a
- N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ ƒë∆°n h√†ng, h·ªç ƒëang t√¨m ki·∫øm th√¥ng tin v·ªÅ ƒë∆°n h√†ng c·ªßa h·ªç
- N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ s·∫£n ph·∫©m c·ª• th·ªÉ nh∆∞ "sinh t·ªë d√¢u chu·ªëi", h·ªç ƒëang t√¨m ki·∫øm th√¥ng tin v·ªÅ s·∫£n ph·∫©m ƒë√≥
- N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ ƒë·∫∑c ƒëi·ªÉm s·∫£n ph·∫©m nh∆∞ "c√† ph√™ n√†o √≠t ƒë∆∞·ªùng nh·∫•t", h·ªç ƒëang t√¨m ki·∫øm s·∫£n ph·∫©m ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ª• th·ªÉ

Tr·∫£ l·ªùi NG·∫ÆN G·ªåN trong 1-2 c√¢u, ch·ªâ n√™u √Ω ƒë·ªãnh th·ª±c s·ª± c·ªßa ng∆∞·ªùi d√πng, kh√¥ng th√™m b·∫•t k·ª≥ gi·∫£i th√≠ch n√†o kh√°c.

√ù ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng:"""

        # L∆∞u temperature hi·ªán t·∫°i
        current_temp = getattr(gemini_client, '_temperature', 0.0)

        try:
            # ƒê·∫∑t temperature th·∫•p h∆°n cho vi·ªác suy lu·∫≠n √Ω ƒë·ªãnh
            gemini_client._temperature = 0.1

            # G·ªçi LLM ƒë·ªÉ suy lu·∫≠n √Ω ƒë·ªãnh
            response = gemini_client.generate_text(prompt)

            # Tr·∫£ v·ªÅ √Ω ƒë·ªãnh ƒë∆∞·ª£c suy lu·∫≠n
            inferred_intent = response.strip()
            log_info(f"üß† Inferred intent from LLM: {inferred_intent}")

            return inferred_intent

        finally:
            # Kh√¥i ph·ª•c temperature ban ƒë·∫ßu
            gemini_client._temperature = current_temp

    except Exception as e:
        log_error(f"Error getting intent from LLM: {str(e)}")
        return f"T√¨m ki·∫øm th√¥ng tin v·ªÅ {question}"
